"use strict";(self.webpackChunkmesodocs=self.webpackChunkmesodocs||[]).push([[7934],{4137:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>h});var r=t(7294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var u=r.createContext({}),l=function(e){var n=r.useContext(u),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},c=function(e){var n=l(e.components);return r.createElement(u.Provider,{value:n},e.children)},p="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},m=r.forwardRef((function(e,n){var t=e.components,a=e.mdxType,o=e.originalType,u=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),p=l(t),m=a,h=p["".concat(u,".").concat(m)]||p[m]||d[m]||o;return t?r.createElement(h,i(i({ref:n},c),{},{components:t})):r.createElement(h,i({ref:n},c))}));function h(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=t.length,i=new Array(o);i[0]=m;var s={};for(var u in n)hasOwnProperty.call(n,u)&&(s[u]=n[u]);s.originalType=e,s[p]="string"==typeof e?e:a,i[1]=s;for(var l=2;l<o;l++)i[l]=t[l];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}m.displayName="MDXCreateElement"},425:(e,n,t)=>{t.d(n,{Z:()=>i});var r=t(7294),a=t(6010);const o={tabItem:"tabItem_Ymn6"};function i(e){let{children:n,hidden:t,className:i}=e;return r.createElement("div",{role:"tabpanel",className:(0,a.Z)(o.tabItem,i),hidden:t},n)}},3992:(e,n,t)=>{t.d(n,{Z:()=>g});var r=t(7462),a=t(7294),o=t(6010),i=t(2957),s=t(6550),u=t(5238),l=t(3609),c=t(2560);function p(e){return function(e){return a.Children.map(e,(e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:n,label:t,attributes:r,default:a}}=e;return{value:n,label:t,attributes:r,default:a}}))}function d(e){const{values:n,children:t}=e;return(0,a.useMemo)((()=>{const e=n??p(t);return function(e){const n=(0,l.l)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function m(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function h(e){let{queryString:n=!1,groupId:t}=e;const r=(0,s.k6)(),o=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,u._X)(o),(0,a.useCallback)((e=>{if(!o)return;const n=new URLSearchParams(r.location.search);n.set(o,e),r.replace({...r.location,search:n.toString()})}),[o,r])]}function b(e){const{defaultValue:n,queryString:t=!1,groupId:r}=e,o=d(e),[i,s]=(0,a.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!m({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const r=t.find((e=>e.default))??t[0];if(!r)throw new Error("Unexpected error: 0 tabValues");return r.value}({defaultValue:n,tabValues:o}))),[u,l]=h({queryString:t,groupId:r}),[p,b]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[r,o]=(0,c.Nk)(t);return[r,(0,a.useCallback)((e=>{t&&o.set(e)}),[t,o])]}({groupId:r}),f=(()=>{const e=u??p;return m({value:e,tabValues:o})?e:null})();(0,a.useLayoutEffect)((()=>{f&&s(f)}),[f]);return{selectedValue:i,selectValue:(0,a.useCallback)((e=>{if(!m({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);s(e),l(e),b(e)}),[l,b,o]),tabValues:o}}var f=t(1048);const v={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function y(e){let{className:n,block:t,selectedValue:s,selectValue:u,tabValues:l}=e;const c=[],{blockElementScrollPositionUntilNextRender:p}=(0,i.o5)(),d=e=>{const n=e.currentTarget,t=c.indexOf(n),r=l[t].value;r!==s&&(p(n),u(r))},m=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const t=c.indexOf(e.currentTarget)+1;n=c[t]??c[0];break}case"ArrowLeft":{const t=c.indexOf(e.currentTarget)-1;n=c[t]??c[c.length-1];break}}n?.focus()};return a.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.Z)("tabs",{"tabs--block":t},n)},l.map((e=>{let{value:n,label:t,attributes:i}=e;return a.createElement("li",(0,r.Z)({role:"tab",tabIndex:s===n?0:-1,"aria-selected":s===n,key:n,ref:e=>c.push(e),onKeyDown:m,onClick:d},i,{className:(0,o.Z)("tabs__item",v.tabItem,i?.className,{"tabs__item--active":s===n})}),t??n)})))}function k(e){let{lazy:n,children:t,selectedValue:r}=e;const o=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=o.find((e=>e.props.value===r));return e?(0,a.cloneElement)(e,{className:"margin-top--md"}):null}return a.createElement("div",{className:"margin-top--md"},o.map(((e,n)=>(0,a.cloneElement)(e,{key:n,hidden:e.props.value!==r}))))}function T(e){const n=b(e);return a.createElement("div",{className:(0,o.Z)("tabs-container",v.tabList)},a.createElement(y,(0,r.Z)({},e,n)),a.createElement(k,(0,r.Z)({},e,n)))}function g(e){const n=(0,f.Z)();return a.createElement(T,(0,r.Z)({key:String(n)},e))}},5037:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>u,default:()=>h,frontMatter:()=>s,metadata:()=>l,toc:()=>p});var r=t(7462),a=(t(7294),t(4137)),o=t(3992),i=t(425);const s={title:"PyTorch",sidebar_position:4},u=void 0,l={unversionedId:"arch_exp/turpan/logiciels/envpython/pytorch",id:"arch_exp/turpan/logiciels/envpython/pytorch",title:"PyTorch",description:"L'installation de PyTorch par pip ou conda sur l'architecture ARM (aarch64) installe uniquement une version CPU. Pour permettre une utilisation GPU, nous avons cr\xe9\xe9 un conteneur apptainer en adaptant pour TURPAN le conteneur pytorch de Nvidia depuis le NGC. Il contient l'ensemble des programmes et librairies d\xe9crit ici//docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-24-02.html",source:"@site/docs/arch_exp/turpan/logiciels/envpython/pytorch.md",sourceDirName:"arch_exp/turpan/logiciels/envpython",slug:"/arch_exp/turpan/logiciels/envpython/pytorch",permalink:"/documentation/user-documentation/arch_exp/turpan/logiciels/envpython/pytorch",draft:!1,tags:[],version:"current",sidebarPosition:4,frontMatter:{title:"PyTorch",sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"Python tools",permalink:"/documentation/user-documentation/arch_exp/turpan/logiciels/envpython/python-tools"},next:{title:"TensorFlow",permalink:"/documentation/user-documentation/arch_exp/turpan/logiciels/envpython/tensorflow"}},c={},p=[{value:"Utilisation du conteneur pytorch",id:"utilisation-du-conteneur-pytorch",level:2},{value:"Pour plus d&#39;information",id:"pour-plus-dinformation",level:2},{value:"Pytorch et modules python suppl\xe9mentaires",id:"pytorch-et-modules-python-suppl\xe9mentaires",level:2}],d={toc:p},m="wrapper";function h(e){let{components:n,...s}=e;return(0,a.kt)(m,(0,r.Z)({},d,s,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"L'installation de PyTorch par pip ou conda sur l'architecture ARM (aarch64) installe uniquement une version CPU. Pour permettre une utilisation GPU, nous avons cr\xe9\xe9 un conteneur apptainer en adaptant pour TURPAN le conteneur pytorch de Nvidia depuis le NGC. Il contient l'ensemble des programmes et librairies d\xe9crit ici : ",(0,a.kt)("a",{parentName:"p",href:"https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-24-02.html"},"https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-24-02.html")),(0,a.kt)("h2",{id:"utilisation-du-conteneur-pytorch"},"Utilisation du conteneur pytorch"),(0,a.kt)("p",null,"Il y a deux fa\xe7ons d'utiliser ce conteneur :"),(0,a.kt)(o.Z,{mdxType:"Tabs"},(0,a.kt)(i.Z,{label:"Mode sbatch",value:"sbatch",default:!0,mdxType:"TabItem"},(0,a.kt)("p",null,"Vous pouvez utiliser le conteneur dans un script sbatch. Dans l'exemple ci-dessous avec une r\xe9servation de 1 c\u0153ur CPU et 1 GPU :"),(0,a.kt)("blockquote",null,(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",{parentName:"pre"},"#!/bin/bash\n#SBATCH -J mon_job\n#SBATCH -p shared\n#SBATCH --nodes 1\n#SBATCH --ntasks 1\n#SBATCH --time=0:15:00\n#SBATCH --gres=gpu:1\n\napptainer exec --bind /tmpdir,/work --nv /work/conteneurs/sessions-interactives/pytorch-24.02-py3-calmip-si.sif python mon_script.py\n")))),(0,a.kt)(i.Z,{label:"Mode interractif",value:"interractif",mdxType:"TabItem"},(0,a.kt)("p",null,"Vous pouvez utiliser le conteneur interactif (pour tester ou installer d'autres outils ou configurer votre environnement). Dans l'exemple ci-dessous avec une demande de ressources de 1 c\u0153ur CPU et 1 GPU :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'srun -p shared -n1 --gres=gpu:1 --pty apptainer shell --bind /tmpdir,/work --nv /work/conteneurs/sessions-interactives/pytorch-24.02-py3-calmip-si.sif\nApptainer> python\nPython 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0] on linux\nType "help", "copyright", "credits" or "license" for more information.\n>>> import torch\n>>> # Pour v\xe9rifier que vos ressources GPU sont bien visibles depuis pytorch\n>>> torch.cuda.current_device()\n0\n>>> torch.cuda.device(0)\n<torch.cuda.device object at 0x4000154a7580>\n>>> torch.cuda.device_count()\n1\n>>> torch.cuda.get_device_name(0)\n\'NVIDIA A100 80GB PCIe\'\n>>> torch.cuda.is_available()\nTrue\n[...]\n>>> # Vos commandes python\n[...]\n')))),(0,a.kt)("admonition",{type:"info"},(0,a.kt)("p",{parentName:"admonition"},"Le conteneur n'a acc\xe8s par d\xe9faut qu'\xe0 votre espace $HOME. Si vous avez besoin des espaces WORK ",(0,a.kt)("inlineCode",{parentName:"p"},"/work")," ou SCRATCH ",(0,a.kt)("inlineCode",{parentName:"p"},"/tmpdir")," vous pouvez les accrocher en utilisant l'option ",(0,a.kt)("inlineCode",{parentName:"p"},"--bind")," d'Apptainer par exemple :"),(0,a.kt)("pre",{parentName:"admonition"},(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"apptainer exec --bind /tmpdir,/work  --nv ...\n"))),(0,a.kt)("p",null,"Exemple de script sbatch pour utiliser pytorch avec le lanceur torchrun en multi-noeuds sur Turpan :"),(0,a.kt)("blockquote",null,(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",{parentName:"pre"},'#!/bin/bash\n\n#SBATCH --job-name=multinode-example\n#SBATCH --nodes=2\n#SBATCH --ntasks=2\n#SBATCH --ntasks-per-node=1\n#SBATCH --gpus-per-task=2\n#SBATCH --gres=gpu:2\n#SBATCH --cpus-per-task=4\n\nset -x\nsleep 10\n\nexport MASTER_PORT=$(echo "${SLURM_JOB_ID} % 100000 % 50000 + 10001" | bc)\nexport MASTER_ADDR=$(hostname --ip-address)\necho "MASTER_ADDR:MASTER_PORT="${MASTER_ADDR}:${MASTER_PORT}\nexport LOGLEVEL=DEBUG\n\necho "HOSTNAME: $(hostname)"\necho "NODES : ${SLURM_JOB_NODELIST}"\n\nsrun apptainer exec --bind /tmpdir,/work --nv /work/conteneurs/sessions-interactives/pytorch-24.02-py3-calmip-si.sif torchrun \\\n--nnodes ${SLURM_NNODES} \\\n--nproc_per_node 2 \\\n--rdzv_id ${RANDOM} \\\n--rdzv_backend c10d \\\n--rdzv_endpoint "${MASTER_ADDR}:${MASTER_PORT}" \\\n./multinode.py 2000 1000\n'))),(0,a.kt)("p",null,"Le script et le dataset d'exemple est disponible ici : ",(0,a.kt)("a",{target:"_blank",href:t(401).Z},"torchrun-turpan.tgz (TGZ - 2 ko)"),(0,a.kt)("br",{parentName:"p"}),"\n","Plusieurs scripts sbatch sont fournis avec diff\xe9rentes configurations en termes de nombre de n\u0153uds et de GPUs."),(0,a.kt)("h2",{id:"pour-plus-dinformation"},"Pour plus d'information"),(0,a.kt)("p",null,"Pour plus d'information sur l'utilisation des conteneurs Apptainer :"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"La documentation de l'",(0,a.kt)("a",{parentName:"li",href:"../apptainer.md"},"utilisation des conteneurs Apptainer sur Turpan")),(0,a.kt)("li",{parentName:"ul"},"La documentation officeille d'Apptainer : ",(0,a.kt)("a",{parentName:"li",href:"https://apptainer.org/docs/user/1.1/"},"https://apptainer.org/docs/user/1.1/"))),(0,a.kt)("h2",{id:"pytorch-et-modules-python-suppl\xe9mentaires"},"Pytorch et modules python suppl\xe9mentaires"),(0,a.kt)("p",null,"Utilisez la commande ",(0,a.kt)("inlineCode",{parentName:"p"},"conda env list")," pour trouver le chemin de votre environnement Conda"),(0,a.kt)("blockquote",null,(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",{parentName:"pre"},"$ conda env list \n# conda environments:\nmyenv3                 /users/sysadmin/user_name/.conda/envs/myenv3\nbase                   /usr/local/miniconda/25.1.1\npython-3.10.9          /usr/local/miniconda/25.1.1/envs/python-3.10.9\npython-tools-3.10.9    /usr/local/miniconda/25.1.1/envs/python-tools-3.10.9\n"))),(0,a.kt)("p",null,"Le chemin sera ensuite utilis\xe9 pour l\u2019ajouter au conteneur Apptainer, comme montr\xe9 dans le script suivant."),(0,a.kt)("blockquote",null,(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",{parentName:"pre"},"#!/bin/bash\n#SBATCH -J mon_job\n#SBATCH -p shared\n#SBATCH --nodes 1\n#SBATCH --ntasks 1\n#SBATCH --time=0:15:00\n#SBATCH --gres=gpu:1\n\nENV_PATH=/tmpdir/user_name/.conda/envs/myenv3\n\nsrun apptainer exec \\\n --nv \\\n --bind /tmpdir,/work \\\n --env PYTHONUSERBASE=$ENV_PATH \\\n --env LD_LIBRARY_PATH=$ENV_PATH/lib:$LD_LIBRARY_PATH \\\n --env PYTHONPATH=$ENV_PATH/lib/python3.10/site-packages:$PYTHONPATH \\\n /work/conteneurs/sessions-interactives/pytorch-24.02-py3-calmip-si.sif \\\n python mon_script.py\n"))))}h.isMDXComponent=!0},401:(e,n,t)=>{t.d(n,{Z:()=>r});const r=t.p+"assets/files/torchrun-turpan-37e73632412a03d3bfdf9ef60198c5f6.tgz"}}]);