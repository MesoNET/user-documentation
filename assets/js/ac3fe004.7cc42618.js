"use strict";(self.webpackChunkmesodocs=self.webpackChunkmesodocs||[]).push([[102],{4137:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>h});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},l=Object.keys(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var o=a.createContext({}),u=function(e){var t=a.useContext(o),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=u(e.components);return a.createElement(o.Provider,{value:t},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,l=e.originalType,o=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),c=u(n),m=r,h=c["".concat(o,".").concat(m)]||c[m]||d[m]||l;return n?a.createElement(h,i(i({ref:t},p),{},{components:n})):a.createElement(h,i({ref:t},p))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=n.length,i=new Array(l);i[0]=m;var s={};for(var o in t)hasOwnProperty.call(t,o)&&(s[o]=t[o]);s.originalType=e,s[c]="string"==typeof e?e:r,i[1]=s;for(var u=2;u<l;u++)i[u]=n[u];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},425:(e,t,n)=>{n.d(t,{Z:()=>i});var a=n(7294),r=n(6010);const l={tabItem:"tabItem_Ymn6"};function i(e){let{children:t,hidden:n,className:i}=e;return a.createElement("div",{role:"tabpanel",className:(0,r.Z)(l.tabItem,i),hidden:n},t)}},3992:(e,t,n)=>{n.d(t,{Z:()=>N});var a=n(7462),r=n(7294),l=n(6010),i=n(2957),s=n(6550),o=n(5238),u=n(3609),p=n(2560);function c(e){return function(e){return r.Children.map(e,(e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:t,label:n,attributes:a,default:r}}=e;return{value:t,label:n,attributes:a,default:r}}))}function d(e){const{values:t,children:n}=e;return(0,r.useMemo)((()=>{const e=t??c(n);return function(e){const t=(0,u.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function m(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function h(e){let{queryString:t=!1,groupId:n}=e;const a=(0,s.k6)(),l=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,o._X)(l),(0,r.useCallback)((e=>{if(!l)return;const t=new URLSearchParams(a.location.search);t.set(l,e),a.replace({...a.location,search:t.toString()})}),[l,a])]}function k(e){const{defaultValue:t,queryString:n=!1,groupId:a}=e,l=d(e),[i,s]=(0,r.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!m({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const a=n.find((e=>e.default))??n[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:t,tabValues:l}))),[o,u]=h({queryString:n,groupId:a}),[c,k]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[a,l]=(0,p.Nk)(n);return[a,(0,r.useCallback)((e=>{n&&l.set(e)}),[n,l])]}({groupId:a}),g=(()=>{const e=o??c;return m({value:e,tabValues:l})?e:null})();(0,r.useLayoutEffect)((()=>{g&&s(g)}),[g]);return{selectedValue:i,selectValue:(0,r.useCallback)((e=>{if(!m({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);s(e),u(e),k(e)}),[u,k,l]),tabValues:l}}var g=n(1048);const f={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function b(e){let{className:t,block:n,selectedValue:s,selectValue:o,tabValues:u}=e;const p=[],{blockElementScrollPositionUntilNextRender:c}=(0,i.o5)(),d=e=>{const t=e.currentTarget,n=p.indexOf(t),a=u[n].value;a!==s&&(c(t),o(a))},m=e=>{let t=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const n=p.indexOf(e.currentTarget)+1;t=p[n]??p[0];break}case"ArrowLeft":{const n=p.indexOf(e.currentTarget)-1;t=p[n]??p[p.length-1];break}}t?.focus()};return r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,l.Z)("tabs",{"tabs--block":n},t)},u.map((e=>{let{value:t,label:n,attributes:i}=e;return r.createElement("li",(0,a.Z)({role:"tab",tabIndex:s===t?0:-1,"aria-selected":s===t,key:t,ref:e=>p.push(e),onKeyDown:m,onClick:d},i,{className:(0,l.Z)("tabs__item",f.tabItem,i?.className,{"tabs__item--active":s===t})}),n??t)})))}function _(e){let{lazy:t,children:n,selectedValue:a}=e;const l=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=l.find((e=>e.props.value===a));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return r.createElement("div",{className:"margin-top--md"},l.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==a}))))}function v(e){const t=k(e);return r.createElement("div",{className:(0,l.Z)("tabs-container",f.tabList)},r.createElement(b,(0,a.Z)({},e,t)),r.createElement(_,(0,a.Z)({},e,t)))}function N(e){const t=(0,g.Z)();return r.createElement(v,(0,a.Z)({key:String(t)},e))}},3528:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>o,contentTitle:()=>i,default:()=>d,frontMatter:()=>l,metadata:()=>s,toc:()=>u});var a=n(7462),r=(n(7294),n(4137));n(3992),n(425);const l={title:"Flow Matching",description:"Guide complet pour ex\xe9cuter facebookresearch/flow_matching sur Turpan."},i="Flow Matching sur Turpan",s={unversionedId:"arch_exp/turpan/ressources_ia/flow_matching",id:"arch_exp/turpan/ressources_ia/flow_matching",title:"Flow Matching",description:"Guide complet pour ex\xe9cuter facebookresearch/flow_matching sur Turpan.",source:"@site/docs/arch_exp/turpan/ressources_ia/flow_matching.md",sourceDirName:"arch_exp/turpan/ressources_ia",slug:"/arch_exp/turpan/ressources_ia/flow_matching",permalink:"/documentation/user-documentation/arch_exp/turpan/ressources_ia/flow_matching",draft:!1,tags:[],version:"current",frontMatter:{title:"Flow Matching",description:"Guide complet pour ex\xe9cuter facebookresearch/flow_matching sur Turpan."},sidebar:"tutorialSidebar",previous:{title:"Ray Tune",permalink:"/documentation/user-documentation/arch_exp/turpan/ressources_ia/HPO/ray_tune"},next:{title:"Lancer un calcul",permalink:"/documentation/user-documentation/arch_exp/turpan/soumettre_calcul/"}},o={},u=[{value:"Preparation du projet. Recuperation du dossier + installation de dependences.",id:"preparation-du-projet-recuperation-du-dossier--installation-de-dependences",level:2},{value:"Lancer le calcul",id:"lancer-le-calcul",level:2},{value:"R\xe9sultats d\u2019ex\xe9cution attendus sur le cluster.",id:"r\xe9sultats-dex\xe9cution-attendus-sur-le-cluster",level:2},{value:"Script d\u2019analyse et de visualisation de l\u2019apprentissage du mod\xe8le process_and_plot_lr_loss.py",id:"script-danalyse-et-de-visualisation-de-lapprentissage-du-mod\xe8le-process_and_plot_lr_losspy",level:2},{value:"Script Slurm pour lancer l\u2019\xe9valuation FID depuis un checkpoint.pth : script_sbatch_evaluation.sh",id:"script-slurm-pour-lancer-l\xe9valuation-fid-depuis-un-checkpointpth--script_sbatch_evaluationsh",level:2},{value:"Script Slurm (Apptainer + multi\u2011n\u0153uds)",id:"script-slurm-apptainer--multin\u0153uds",level:2},{value:"Pr\xe9paration du dataset ImageNet32 (Blurred)",id:"pr\xe9paration-du-dataset-imagenet32-blurred",level:2},{value:"T\xe9l\xe9chargement d&#39;Inception v3 (poids pour FID)",id:"t\xe9l\xe9chargement-dinception-v3-poids-pour-fid",level:2},{value:"Modifications apport\xe9es au code",id:"modifications-apport\xe9es-au-code",level:2},{value:"1) Chargement s\xe9curis\xe9 des checkpoints",id:"1-chargement-s\xe9curis\xe9-des-checkpoints",level:3},{value:"2) Sauvegarde syst\xe9matique du mod\xe8le \xe0 chaque epoch (sans accumuler de fichiers)",id:"2-sauvegarde-syst\xe9matique-du-mod\xe8le-\xe0-chaque-epoch-sans-accumuler-de-fichiers",level:3},{value:"Non utilisation de submitit_train.py",id:"non-utilisation-de-submitit_trainpy",level:2}],p={toc:u},c="wrapper";function d(e){let{components:t,...n}=e;return(0,r.kt)(c,(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"flow-matching-sur-turpan"},"Flow Matching sur Turpan"),(0,r.kt)("p",null,"Ce document facilite l\u2019ex\xe9cution du d\xe9p\xf4t ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/facebookresearch/flow_matching"},"https://github.com/facebookresearch/flow_matching")," sur Turpan. Le contenu du d\xe9p\xf4t GitHub a \xe9t\xe9 copi\xe9 dans un r\xe9pertoire du cluster et adapt\xe9 par plusieurs modifications pratiques est d\xe9sormais disponible dans un r\xe9pertoire d\xe9di\xe9 du cluster pour une utilisation directe."),(0,r.kt)("p",null,"L\u2019exemple reproduit correspond au cas d\u2019images ImageNet32 (Blurred) utilisant un mod\xe8le de type Class-conditional UNet. Le test s\u2019ex\xe9cute sur 900 \xe9poques et atteint un FID de 1.16, tr\xe8s proche de la valeur de r\xe9f\xe9rence 1.14 indiqu\xe9e dans le d\xe9p\xf4t. Cet accord valide la reproduction du test, l\u2019\xe9cart observ\xe9 restant enti\xe8rement dans la variabilit\xe9 attendue pour ce type de mesure."),(0,r.kt)("p",null,"L\u2019article associ\xe9 au d\xe9p\xf4t est disponible ici : ",(0,r.kt)("a",{parentName:"p",href:"https://arxiv.org/pdf/2412.06264"},"https://arxiv.org/pdf/2412.06264")),(0,r.kt)("p",null,"Vous trouvez ici : "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#preparation-du-projet-recuperation-du-dossier--installation-de-dependences"},"Preparation du projet")," "),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#lancer-le-calcul"},"Lancer le calcul")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#r%C3%A9sultats-dex%C3%A9cution-attendus-sur-le-cluster"},"R\xe9sultats d'ex\xe9cution attendus"))),(0,r.kt)("p",null,"Tout est pr\xeat \xe0 copier / coller."),(0,r.kt)("p",null,"Il y a aussi une deuxi\xe8me partie, non indispensable pour ex\xe9cuter le cas test, mais qui offre une vue d\u2019ensemble sur la pr\xe9paration des donn\xe9es et les adaptations du code mises en place pour assurer le bon fonctionnement du cas test et des scripts utiles:\n",(0,r.kt)("strong",{parentName:"p"},"Parametrage du test et pr\xe9paration des donnes:"),"\n",(0,r.kt)("a",{parentName:"p",href:"#details-de-la-mis-en-place-du-test"},"D\xe9tails du test")," |\n",(0,r.kt)("a",{parentName:"p",href:"#script-slurm-apptainer--multin%C5%93uds"},"Slurm multi-n\u0153uds")," |\n",(0,r.kt)("a",{parentName:"p",href:"#pr%C3%A9paration-du-dataset-imagenet32-blurred"},"Dataset ImageNet32")," |\n",(0,r.kt)("a",{parentName:"p",href:"#t%C3%A9l%C3%A9chargement-dinception-v3-poids-pour-fid"},"Inception v3 FID")," |\n",(0,r.kt)("strong",{parentName:"p"},"Changements sur code source:")," ",(0,r.kt)("a",{parentName:"p",href:"#modifications-apport%C3%A9es-au-code"},"Modifications du code")," |\n",(0,r.kt)("a",{parentName:"p",href:"#non-utilisation-de-submitit_trainpy"},"Pas de submitit.py")," |\n",(0,r.kt)("strong",{parentName:"p"},"Scripts et outils d\u2019analyse:")," ",(0,r.kt)("a",{parentName:"p",href:"#script-danalyse-et-de-visualisation-de-lapprentissage-du-mod%C3%A8le-process_and_plot_lr_losspy"},"Script d\u2019analyse et de visualisation")," | ",(0,r.kt)("a",{parentName:"p",href:"#script-slurm-pour-lancer-l%C3%A9valuation-fid-depuis-un-checkpointpth--script_sbatch_evaluationsh"},"ExtraScript Slurm FID")," |"),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"preparation-du-projet-recuperation-du-dossier--installation-de-dependences"},"Preparation du projet. Recuperation du dossier + installation de dependences."),(0,r.kt)("p",null,"Pour faciliter le d\xe9ploiement, le code modifi\xe9 ainsi que le dataset ImageNet et sa version transform\xe9e en 32 blurred sont directement accessibles sur le cluster.\nLes modifications r\xe9alis\xe9es ainsi que les commandes n\xe9cessaires pour pr\xe9parer ce r\xe9pertoire sont sp\xe9cifi\xe9es en bas de cette page."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"tar xf /work/shares/IA-Tests/flow_matching_facebook.tar.gz  # Cela prends ~ 43 minutes\ncd flow_matching_facebook\napptainer shell --nv --bind /tmpdir,/work --nv /work/conteneurs/sessions-interactives/pytorch-25.01-py3-calmip-si-latest.sif\nApptainer> pip install -e .\n\nCntrl + d  //Pour sortir du container\n")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"lancer-le-calcul"},"Lancer le calcul"),(0,r.kt)("p",null,"Pour d\xe9marrer l\u2019entra\xeenement, il suffit d\u2019ex\xe9cuter :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"cd flow_matching_facebook/examples/image\nsbatch script_sbatch.sh\n")),(0,r.kt)("p",null,"Ce script lance automatiquement le code en mode distribu\xe9 sur le nombre de n\u0153uds et avec 2 GPUs par n\u0153ud.\nLe seul param\xe8tre \xe0 modifier pour changer le nombre total de n\u0153uds/GPUs utilis\xe9s est"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"#SBATCH --nodes=6\n")),(0,r.kt)("h3",{style:{fontSize:"1.1rem"}}," Le processus complet est donc le suivant "),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Lancer le premier job :")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"sbatch script_sbatch.sh\n")),(0,r.kt)("p",null,"Cela vous donne un ",(0,r.kt)("inlineCode",{parentName:"p"},"<FIRST_JOBID>")),(0,r.kt)("ol",{start:2},(0,r.kt)("li",{parentName:"ol"},"Lancer plusieurs ex\xe9cutions avec d\xe9pendances (10 fois dans cet exemple) :")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"./launch_chain.sh 10 script_sbatch.sh <FIRST_JOBID>\n")),(0,r.kt)("p",null,"La partition small a un temps d\u2019ex\xe9cution maximal de 4 heures. Pour lancer un entra\xeenement long, ce script encha\xeene plusieurs jobs Slurm avec des d\xe9pendances.\nLorsqu\u2019un job se termine, le suivant reprend l\u2019entra\xeenement l\xe0 o\xf9 le pr\xe9c\xe9dent s\u2019\xe9tait arr\xeat\xe9."),(0,r.kt)("ol",{start:3},(0,r.kt)("li",{parentName:"ol"},"V\xe9rifier que tout est en place :")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"squeue --me\n")),(0,r.kt)("h2",{id:"r\xe9sultats-dex\xe9cution-attendus-sur-le-cluster"},"R\xe9sultats d\u2019ex\xe9cution attendus sur le cluster."),(0,r.kt)("p",null,"Cet exemple pr\xe9sente les performances obtenues lors de l\u2019entra\xeenement du mod\xe8le Class-Conditional U-Net sur ImageNet32 (blurred) en utilisant :"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"6 n\u0153uds Turpan"),(0,r.kt)("li",{parentName:"ul"},"12 GPU NVIDIA A100 (80 Go) ")),(0,r.kt)("p",null,"et les options suivantes du script train.py :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'        --lr 4e-4 \\\n        --batch_size 512 \\\n        --eval_frequency 100 \\\n        --accum_iter 1 \\\n        --decay_lr \\\n        --compute_fid \\\n        --ode_method dopri5 \\\n        --ode_options \'{\\"atol\\": 1e-5, \\"rtol\\":1e-5}\' \\\n')),(0,r.kt)("p",null,"C'est le deuxieme test du tableau: ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("a",{parentName:"strong",href:"https://github.com/facebookresearch/flow_matching/tree/main/examples/image"},"https://github.com/facebookresearch/flow_matching/tree/main/examples/image")),"\nLe batch_size est incremente pour accelerer le calcul et le learning rate est modifie en consequence. ",(0,r.kt)("a",{parentName:"p",href:"#details-de-la-mis-en-place-du-test"},"Voir la section \u201cDetails de la mis en place du test\u201d")),(0,r.kt)("admonition",{title:"R\xe9sultats",type:"info"},(0,r.kt)("p",{parentName:"admonition"},(0,r.kt)("strong",{parentName:"p"},"Temps d\u2019ex\xe9cution :"),(0,r.kt)("br",{parentName:"p"}),"\n","900 it\xe9rations \u2192 ",(0,r.kt)("strong",{parentName:"p"},"~65 h")," (2 jours et 17 heures)"),(0,r.kt)("p",{parentName:"admonition"},(0,r.kt)("strong",{parentName:"p"},"FID obtenu :"),(0,r.kt)("br",{parentName:"p"}),"\n",(0,r.kt)("strong",{parentName:"p"},"1.16")," ce qui est tr\xe8s proche du score de r\xe9f\xe9rence (1,14) et se situe pleinement dans la variabilit\xe9 normale de la mesure.")),(0,r.kt)("h2",{id:"script-danalyse-et-de-visualisation-de-lapprentissage-du-mod\xe8le-process_and_plot_lr_losspy"},"Script d\u2019analyse et de visualisation de l\u2019apprentissage du mod\xe8le process_and_plot_lr_loss.py"),(0,r.kt)("p",null,"Ce script a \xe9t\xe9 con\xe7u pour faciliter le suivi de l\u2019apprentissage d\u2019un mod\xe8le pendant son entra\xeenement. Il automatise trois \xe9tapes essentielles :"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Rassembler et nettoyer les logs\nLe script parcourt tous les fichiers slurm-*.out g\xe9n\xe9r\xe9s lors des diff\xe9rentes ex\xe9cutions du job.\nIl n\u2019en extrait que les lignes r\xe9ellement utiles : celles contenant l\u2019\xe9poque, la loss et le learning rate.\nCes lignes filtr\xe9es sont ensuite regroup\xe9es dans un fichier unique, clean_log.txt, ce qui permet d\u2019avoir un historique clair et lisible de l\u2019entra\xeenement."),(0,r.kt)("li",{parentName:"ol"},"Parser les informations importantes\n\xc0 partir du fichier nettoy\xe9, le script reconstruit l\u2019\xe9volution :")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"de l\u2019\xe9poque (sous forme fractionnaire, pour afficher la progression intra-\xe9poque),"),(0,r.kt)("li",{parentName:"ul"},"de la loss,"),(0,r.kt)("li",{parentName:"ul"},"du learning rate.\nCela permet d\u2019obtenir une s\xe9rie temporelle continue, m\xeame lorsque l\u2019entra\xeenement s\u2019\xe9tale sur plusieurs fichiers Slurm.")),(0,r.kt)("ol",{start:3},(0,r.kt)("li",{parentName:"ol"},"G\xe9n\xe9rer des graphiques automatiquement\nDeux courbes sont produites et enregistr\xe9es dans des images PNG :")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"loss_plot.png : \xe9volution de la perte au fil de l\u2019entra\xeenement,"),(0,r.kt)("li",{parentName:"ul"},"lr_plot.png : \xe9volution du learning rate.\nCes graphiques permettent de visualiser imm\xe9diatement si l\u2019apprentissage progresse correctement, si la loss converge ou si la politique de learning rate fonctionne comme pr\xe9vu.")),(0,r.kt)("p",null,"Ce script est donc un outil pratique pour surveiller rapidement l\u2019\xe9tat de l\u2019entra\xeenement, diagnostiquer des probl\xe8mes \xe9ventuels (learning rate trop \xe9lev\xe9, stagnation, divergence\u2026) et visualiser la dynamique du mod\xe8le au fil du temps."),(0,r.kt)("p",null,"Pour l'utiliser:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"module load conda\nconda activate python-tools-3.10.9\n\npython process_and_plot_lr_loss.py\n")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"script-slurm-pour-lancer-l\xe9valuation-fid-depuis-un-checkpointpth--script_sbatch_evaluationsh"},"Script Slurm pour lancer l\u2019\xe9valuation FID depuis un checkpoint.pth : script_sbatch_evaluation.sh"),(0,r.kt)("p",null,"Ce script Slurm sert \xe0 lancer automatiquement l\u2019\xe9valuation FID du mod\xe8le sur un GPU."),(0,r.kt)("p",null,"Il ex\xe9cute :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"python evaluate_fid.py \\\n    --checkpoint output_dir/checkpoint.pth \\\n    --num_images 50000 \\\n    --batch_size 4000 \\ # Pour bien remplir le GPU sur une A100 80GB\n    --data_path data/train_blurred_32/box/\n")),(0,r.kt)("p",null,"Cela d\xe9clenche la g\xe9n\xe9ration d\u2019images et le calcul du FID."),(0,r.kt)("p",null,"Pour l'utiliser:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"sbatch script_sbatch_evaluation.sh\n")),(0,r.kt)("p",null,"Details du script:\nCe script r\xe9alise l\u2019\xe9valuation du mod\xe8le en plusieurs \xe9tapes :"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Chargement des param\xe8tres d\u2019entra\xeenement")),(0,r.kt)("p",null,"\xc0 partir de args.json, il r\xe9cup\xe8re toutes les options utilis\xe9es lors du training, afin de reconstruire la m\xeame architecture et il prends en compte le dernier checkpoint g\xe9n\xe9r\xe9 du mod\xe8le."),(0,r.kt)("ol",{start:2},(0,r.kt)("li",{parentName:"ol"},"Chargement du mod\xe8le")),(0,r.kt)("p",null,"\xc0 partir du output_dir/checkpoint.pth :"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"r\xe9cup\xe9ration des poids,"),(0,r.kt)("li",{parentName:"ul"},"reconstruction de l\u2019architecture (Flow-Matching),")),(0,r.kt)("ol",{start:3},(0,r.kt)("li",{parentName:"ol"},"Construction du dataset r\xe9el")),(0,r.kt)("p",null,"Utilise ImageFolder et les m\xeames transformations que pendant l\u2019entra\xeenement, pour garantir une comparaison correcte."),(0,r.kt)("ol",{start:4},(0,r.kt)("li",{parentName:"ol"},"Calcul du FID")),(0,r.kt)("p",null,"Appelle eval_model, qui :\n\u2022\tg\xe9n\xe8re num_images images,\n\u2022\tcalcule les statistiques r\xe9elles et g\xe9n\xe9r\xe9es,\n\u2022\tproduit le score FID."),(0,r.kt)("ol",{start:5},(0,r.kt)("li",{parentName:"ol"},"Sauvegarde des r\xe9sultats")),(0,r.kt)("p",null,"Le FID est enregistr\xe9 dans fid_results.json."),(0,r.kt)("hr",null),(0,r.kt)("h1",{id:"details-de-la-mis-en-place-du-test"},"Details de la mis en place du test"),(0,r.kt)("p",null,"Pour am\xe9liorer l\u2019efficacit\xe9 globale de l\u2019entra\xeenement, le batch size est augment\xe9 autant que le permet la m\xe9moire GPU disponible. Un batch size plus \xe9lev\xe9 permet d\u2019am\xe9liorer l\u2019efficacit\xe9 du calcul, de mieux exploiter le parall\xe9lisme du GPU et de r\xe9duire le temps total d\u2019entra\xeenement par epoch.\nLorsque le batch size est fortement augment\xe9, il est n\xe9cessaire d\u2019ajuster le learning rate afin de conserver une dynamique d\u2019apprentissage stable. Une r\xe8gle couramment utilis\xe9e consiste \xe0 adapter le learning rate en fonction de la racine carr\xe9e du facteur d\u2019augmentation du batch size."),(0,r.kt)("p",null,"Cas de base :"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Batch size d\u2019origine : 32"),(0,r.kt)("li",{parentName:"ul"},"Nouveau batch size : 512"),(0,r.kt)("li",{parentName:"ul"},"Learning rate d\u2019origine : 1\xd710\u207b\u2074")),(0,r.kt)("p",null,"Le ratio entre les deux batch sizes est :"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"512 / 32 = 16"),(0,r.kt)("li",{parentName:"ul"},"La racine carr\xe9e de 16 est 4.")),(0,r.kt)("p",null,"Donc le nouveau learning rate est :"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"LR_nouveau = 1\xd710\u207b\u2074 \xd7 4 = 4\xd710\u207b\u2074")),(0,r.kt)("p",null,"Ainsi, avec un batch size de 512 le learning rate utilis\xe9 est 4\xd710\u207b\u2074."),(0,r.kt)("h2",{id:"script-slurm-apptainer--multin\u0153uds"},"Script Slurm (Apptainer + multi\u2011n\u0153uds)"),(0,r.kt)("p",null,"Ici le sbatch script que utilis\xe9 :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'#!/bin/bash\n#SBATCH --job-name=flowmatching\n#SBATCH --nodes=6\n#SBATCH --ntasks=12\n#SBATCH --ntasks-per-node=2\n#SBATCH --gres=gpu:2\n#SBATCH --cpus-per-task=10\n#SBATCH --time=04:00:00\n#SBATCH -p small\n# -------------------------------------------------------\n# 1. Setup Environment Variables (Replaces submitit logic)\n# -------------------------------------------------------\n\n...\n\n# Setup Output Directory (mimics args.job_dir / args.output_dir)\n# Really important!! This is the path used to restart the job from a checkpoint\nJOB_DIR="output_dir"\necho "Output Directory: $JOB_DIR"\n\n# IMPORTANT: WORLD_SIZE must match ntasks (6 nodes * 2 tasks = 12)\nexport WORLD_SIZE=$(( SLURM_NNODES * SLURM_NTASKS_PER_NODE ))\n\n# -------------------------------------------------------\n# 2. Setup Distributed Initialization (mimics get_init_file)\n# -------------------------------------------------------\n\n...\n\n# -------------------------------------------------------\n# 3. TODO After first sbatch execution !!!\n# -------------------------------------------------------\nexport RESUME_PATH= #${JOB_DIR}/checkpoint.pth # Add the path to ${JOB_DIR}/checkpoint.pth only after the first sbatch is submited \nRESUME_FLAG="" \nif [[ -n "$RESUME_PATH" ]]; then\n    RESUME_FLAG="--resume $RESUME_PATH"\nfi\n\n# -------------------------------------------------------\n# 4. Run Command\n# -------------------------------------------------------\n# We use \'srun\' to launch the script on every GPU across all nodes.\n# We map Slurm variables to PyTorch variables so the script knows its rank.\nsrun apptainer exec --nv --bind /tmpdir,/work \\\n    --env TORCH_HOME=$TORCH_HOME \\\n    --env TORCHFIDELITY_HOME=torch_home \\\n    --nv /work/conteneurs/sessions-interactives/pytorch-25.01-py3-calmip-si-latest.sif \\\n    bash -c "\n    # 1. Export Distributed Variables so Python finds them automatically\n    export RANK=\\$SLURM_PROCID\n    export LOCAL_RANK=\\$SLURM_LOCALID\n    export WORLD_SIZE=$WORLD_SIZE\n    export MASTER_ADDR=$MASTER_ADDR\n    export MASTER_PORT=$MASTER_PORT\n\n    echo \\"Rank \\$RANK (Local \\$LOCAL_RANK) on \\$(hostname)\\"\n\n    # 2. Run Python WITHOUT the conflicting flags (--rank, --gpu, --job_dir)\n    python train.py \\\n        --dist_url \'env://\' \\\n        --output_dir \'${JOB_DIR}\' \\\n        ${RESUME_FLAG} \\\n        --data_path \'${IMAGENET_DIR}train_blurred_$IMAGENET_RES/box/\' \\\n        --lr 4e-4 \\\n        --batch_size 512 \\\n        --accum_iter 1 \\\n        --eval_frequency 100 \\\n        --decay_lr \\\n        --compute_fid \\\n        --ode_method dopri5 \\\n        --ode_options \'{\\"atol\\": 1e-5, \\"rtol\\":1e-5}\' \\\n        \\"\\$@\\"\n    "\n')),(0,r.kt)("blockquote",null,(0,r.kt)("admonition",{parentName:"blockquote",type:"info"},(0,r.kt)("ul",{parentName:"admonition"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"WORLD_SIZE")," doit correspondre au nombre total de t\xe2ches (ntasks).  "),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"JOB_DIR")," est crucial : toutes les runs doivent pointer vers un ",(0,r.kt)("inlineCode",{parentName:"li"},"--output_dir")," identique pour reprendre depuis le checkpoint.")))),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"pr\xe9paration-du-dataset-imagenet32-blurred"},"Pr\xe9paration du dataset ImageNet32 (Blurred)"),(0,r.kt)("p",null,"Placer les donn\xe9es sous :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"examples/image/data/\n")),(0,r.kt)("p",null,"T\xe9l\xe9chargement (m\xe9thode g\xe9n\xe9rique) :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"wget https://image-net.org/data/ILSVRC/blurred/train_blurred.tar.gz\n")),(0,r.kt)("p",null,"Si le lien change :"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Cr\xe9ez un compte sur ",(0,r.kt)("a",{parentName:"li",href:"https://image-net.org"},"https://image-net.org"),"  "),(0,r.kt)("li",{parentName:"ol"},"Allez dans ",(0,r.kt)("strong",{parentName:"li"},"Downloads"),"  "),(0,r.kt)("li",{parentName:"ol"},"T\xe9l\xe9charger ",(0,r.kt)("em",{parentName:"li"},"Blurred training images"),"  "),(0,r.kt)("li",{parentName:"ol"},"Clic droit \u2192 ",(0,r.kt)("em",{parentName:"li"},"Copy link")," \u2192 ",(0,r.kt)("inlineCode",{parentName:"li"},"wget <link>"))),(0,r.kt)("p",null,"D\xe9compressez dans : ",(0,r.kt)("inlineCode",{parentName:"p"},"examples/image/data/train_blurred_32/box/")," (ou la r\xe9solution choisie)."),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"t\xe9l\xe9chargement-dinception-v3-poids-pour-fid"},"T\xe9l\xe9chargement d'Inception v3 (poids pour FID)"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"wget https://github.com/toshas/torch-fidelity/releases/download/v0.2.0/weights-inception-2015-12-05-6726825d.pth\n")),(0,r.kt)("p",null,"Les poids sont places dans :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"examples/image/torch_home/hub/checkpoints/\n")),(0,r.kt)("p",null,"La variable TORCH_HOME est d\xe9finie:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"export TORCH_HOME=$PWD/examples/image/torch_home\n")),(0,r.kt)("blockquote",null,(0,r.kt)("admonition",{parentName:"blockquote",type:"info"},(0,r.kt)("p",{parentName:"admonition"},(0,r.kt)("inlineCode",{parentName:"p"},"torch_fidelity")," et ",(0,r.kt)("inlineCode",{parentName:"p"},"torch.hub")," cherchent par d\xe9faut dans ",(0,r.kt)("inlineCode",{parentName:"p"},"$TORCH_HOME/hub/checkpoints/"),". Assurez\u2011vous que le fichier est dans ce dossier et que ",(0,r.kt)("inlineCode",{parentName:"p"},"TORCH_HOME")," est export\xe9 ",(0,r.kt)("strong",{parentName:"p"},"avant")," de lancer l'entra\xeenement."))),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"modifications-apport\xe9es-au-code"},"Modifications apport\xe9es au code"),(0,r.kt)("p",null,"Pour que tout fonctionne sur notre cluster, j'ai appliqu\xe9 les modifications suivantes :"),(0,r.kt)("h3",{id:"1-chargement-s\xe9curis\xe9-des-checkpoints"},"1) Chargement s\xe9curis\xe9 des checkpoints"),(0,r.kt)("p",null,"Dans ",(0,r.kt)("inlineCode",{parentName:"p"},"training/load_and_save.py"),", ligne autour de 54 :",(0,r.kt)("br",{parentName:"p"}),"\n","Remplacez la ligne"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'checkpoint = torch.load(args.resume, map_location="cpu")\n')),(0,r.kt)("p",null,"par :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'checkpoint = torch.load(args.resume, map_location="cpu", weights_only=False)\n')),(0,r.kt)("p",null,"Ceci \xe9vite l'erreur li\xe9e \xe0 ",(0,r.kt)("inlineCode",{parentName:"p"},"argparse.Namespace")," sous les versions r\xe9centes de PyTorch."),(0,r.kt)("h3",{id:"2-sauvegarde-syst\xe9matique-du-mod\xe8le-\xe0-chaque-epoch-sans-accumuler-de-fichiers"},"2) Sauvegarde syst\xe9matique du mod\xe8le \xe0 chaque epoch (sans accumuler de fichiers)"),(0,r.kt)("p",null,"Dans ",(0,r.kt)("inlineCode",{parentName:"p"},"train.py"),", nous activons la sauvegarde automatique \xe0 chaque fin d\u2019epoch pour\ngarantit qu\u2019on peut reprendre l\u2019entra\xeenement \xe0 tout moment depuis le dernier \xe9tat."),(0,r.kt)("p",null,"Le bloc utilis\xe9 est :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# --------------------------------------------------------------------------\n# Save *one* checkpoint at the end of each epoch (overwrite previous)\n# --------------------------------------------------------------------------\nif args.output_dir and distributed_mode.is_main_process():\n    save_model(\n        args=args,\n        model=model,\n        model_without_ddp=model_without_ddp,\n        optimizer=optimizer,\n        lr_schedule=lr_schedule,\n        loss_scaler=loss_scaler,\n        epoch=epoch,\n    )\n# --------------------------------------------------------------------------\n")),(0,r.kt)("p",null,"et dans ",(0,r.kt)("inlineCode",{parentName:"p"},"training/load_and_save.py")," une ligne est comment\xe9 pour pas\nempecher la generation de checkpoint pour chaque epoch et \xe9viter ansi de consommer trop d\u2019inodes dans /tmpdir,"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'checkpoint_paths = [\n#    output_dir / ("checkpoint-%s.pth" % epoch_name),\n    output_dir / "checkpoint.pth",\n]\n\n')),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"non-utilisation-de-submitit_trainpy"},"Non utilisation de submitit_train.py"),(0,r.kt)("admonition",{type:"caution"},(0,r.kt)("ul",{parentName:"admonition"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"submitit_train.py")," dans le repo g\xe9n\xe8re des scripts SLURM qui peuvent ne pas \xeatre conteneur-aware. Dans notre setup Apptainer il \xe9tait plus simple d'appeler ",(0,r.kt)("inlineCode",{parentName:"li"},"train.py")," directement dans le conteneur via ",(0,r.kt)("inlineCode",{parentName:"li"},"srun apptainer exec ..."),"."))),(0,r.kt)("hr",null))}d.isMDXComponent=!0}}]);