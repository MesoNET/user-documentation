"use strict";(self.webpackChunkmesodocs=self.webpackChunkmesodocs||[]).push([[3769],{4137:(e,t,n)=>{n.d(t,{Zo:()=>o,kt:()=>k});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function p(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},l=Object.keys(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var u=a.createContext({}),s=function(e){var t=a.useContext(u),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},o=function(e){var t=s(e.components);return a.createElement(u.Provider,{value:t},e.children)},m="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,l=e.originalType,u=e.parentName,o=p(e,["components","mdxType","originalType","parentName"]),m=s(n),c=r,k=m["".concat(u,".").concat(c)]||m[c]||d[c]||l;return n?a.createElement(k,i(i({ref:t},o),{},{components:n})):a.createElement(k,i({ref:t},o))}));function k(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=n.length,i=new Array(l);i[0]=c;var p={};for(var u in t)hasOwnProperty.call(t,u)&&(p[u]=t[u]);p.originalType=e,p[m]="string"==typeof e?e:r,i[1]=p;for(var s=2;s<l;s++)i[s]=n[s];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},4384:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>u,contentTitle:()=>i,default:()=>d,frontMatter:()=>l,metadata:()=>p,toc:()=>s});var a=n(7462),r=(n(7294),n(4137));const l={},i="Optuna",p={unversionedId:"arch_exp/turpan/ressources_ia/HPO/optuna",id:"arch_exp/turpan/ressources_ia/HPO/optuna",title:"Optuna",description:"Optuna est une biblioth\xe8que d\u2019optimisation d\u2019hyperparam\xe8tres moderne, efficace et tr\xe8s flexible. Elle permet d\u2019explorer automatiquement un espace d\u2019hyperparam\xe8tres, d\u2019utiliser des algorithmes avanc\xe9s comme TPE, CMA-ES ou la recherche par grille, et d\u2019ex\xe9cuter de nombreux essais (\xab trials \xbb) en parall\xe8le.",source:"@site/docs/arch_exp/turpan/ressources_ia/HPO/optuna.md",sourceDirName:"arch_exp/turpan/ressources_ia/HPO",slug:"/arch_exp/turpan/ressources_ia/HPO/optuna",permalink:"/documentation/user-documentation/arch_exp/turpan/ressources_ia/HPO/optuna",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Hyperparameter Optimization (HPO)",permalink:"/documentation/user-documentation/arch_exp/turpan/ressources_ia/HPO/"},next:{title:"Ray Tune",permalink:"/documentation/user-documentation/arch_exp/turpan/ressources_ia/HPO/ray_tune"}},u={},s=[{value:"Copier l&#39;exemple Optuna",id:"copier-lexemple-optuna",level:2},{value:"Structure du r\xe9pertoire",id:"structure-du-r\xe9pertoire",level:2},{value:"Installer Optuna dans le conteneur Turpan",id:"installer-optuna-dans-le-conteneur-turpan",level:2},{value:"Fonctionnement d\u2019Optuna sur Turpan (multi\u2011n\u0153uds)",id:"fonctionnement-doptuna-sur-turpan-multin\u0153uds",level:2},{value:"La fonction <code>objective(trial)</code> \u2014 c\u0153ur d\u2019Optuna",id:"la-fonction-objectivetrial--c\u0153ur-doptuna",level:2},{value:"Pourquoi passer <code>trial</code> \xe0 <code>train_model()</code> ?",id:"pourquoi-passer-trial-\xe0-train_model-",level:3},{value:"Script SBATCH (multi\u2011n\u0153uds, multi\u2011GPU)",id:"script-sbatch-multin\u0153uds-multigpu",level:2},{value:"Comment cela se r\xe9partit ?",id:"comment-cela-se-r\xe9partit-",level:3},{value:"R\xe9cup\xe9rer le meilleur mod\xe8le",id:"r\xe9cup\xe9rer-le-meilleur-mod\xe8le",level:2},{value:"Algorithmes d&#39;optimisation avanc\xe9s dans Optuna",id:"algorithmes-doptimisation-avanc\xe9s-dans-optuna",level:2},{value:"Exemple TPE (par d\xe9faut)",id:"exemple-tpe-par-d\xe9faut",level:3},{value:"Exemple CMA\u2011ES",id:"exemple-cmaes",level:3},{value:"Visualisations Optuna",id:"visualisations-optuna",level:2},{value:"Adapter l\u2019exemple \xe0 des mod\xe8les plus grands (LLM)",id:"adapter-lexemple-\xe0-des-mod\xe8les-plus-grands-llm",level:2},{value:"Lancer le job",id:"lancer-le-job",level:2},{value:"Scalabilit\xe9 attendue sur Turpan",id:"scalabilit\xe9-attendue-sur-turpan",level:2}],o={toc:s},m="wrapper";function d(e){let{components:t,...n}=e;return(0,r.kt)(m,(0,a.Z)({},o,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"optuna"},"Optuna"),(0,r.kt)("p",null,"Optuna est une biblioth\xe8que d\u2019optimisation d\u2019hyperparam\xe8tres moderne, efficace et tr\xe8s flexible. Elle permet d\u2019explorer automatiquement un espace d\u2019hyperparam\xe8tres, d\u2019utiliser des algorithmes avanc\xe9s comme TPE, CMA-ES ou la recherche par grille, et d\u2019ex\xe9cuter de nombreux essais (\xab trials \xbb) en parall\xe8le.",(0,r.kt)("br",{parentName:"p"}),"\n","Contrairement \xe0 Ray Tune, qui fonctionne bien sur un seul n\u0153ud, ",(0,r.kt)("strong",{parentName:"p"},"Optuna supporte naturellement les environnements multi\u2011n\u0153uds sur Turpan"),", via une base de donn\xe9es partag\xe9e SQLite que chaque worker met \xe0 jour. Cela permet de lancer des centaines de trials en parall\xe8le sur plusieurs GPU et plusieurs n\u0153uds."),(0,r.kt)("p",null,"Ce document explique comment utiliser Optuna sur Turpan :  "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#copier-lexemple-optuna"},"copier les fichiers d\u2019exemple")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#structure-du-r%C3%A9pertoire"},"Structure du r\xe9pertoire")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#installer-optuna-dans-le-conteneur-turpan"},"installer Optuna dans le conteneur")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#fonctionnement-doptuna-sur-turpan-multin%C5%93uds"},"fonctionnement d\u2019Optuna sur Turpan (multi\u2011n\u0153uds)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#la-fonction-objectivetrial--c%C5%93ur-doptuna"},"\xe9crire votre fonction ",(0,r.kt)("inlineCode",{parentName:"a"},"objective(trial)")," dynamique")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#script-sbatch-multin%C5%93uds-multigpu"},"Script SBATCH (multi\u2011n\u0153uds, multi\u2011GPU)"),"  "),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#r%C3%A9cup%C3%A9rer-le-meilleur-mod%C3%A8le"},"r\xe9cup\xe9rer le meilleur mod\xe8le")," "),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#algorithmes-doptimisation-avanc%C3%A9s-dans-optuna"},"Algorithmes d'optimisation avanc\xe9s dans Optuna")," "),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#visualisations-optuna"},"Visualisations Optuna")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#adapter-lexemple-%C3%A0-des-mod%C3%A8les-plus-grands-llm"},"Adapter l\u2019exemple \xe0 des mod\xe8les plus grands (LLM)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#lancer-le-job"},"Lancer le job")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#scalabilit%C3%A9-attendue-sur-turpan"},"Scalabilit\xe9 attendue sur Turpan"))),(0,r.kt)("p",null,"Toute la documentation est adapt\xe9e exactement \xe0 l\u2019exemple que nous avons mis en place pour Turpan."),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"copier-lexemple-optuna"},"Copier l'exemple Optuna"),(0,r.kt)("p",null,"Les scripts d\u2019exemple Optuna se trouvent dans :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"/work/shares/IA-Tests/optuna.tar.gz\n")),(0,r.kt)("p",null,"Extraire dans votre espace :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"tar xvf /work/shares/IA-Tests/optuna.tar.gz\n")),(0,r.kt)("p",null,"Le r\xe9pertoire suivant sera cr\xe9\xe9 :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"optuna/\n\u251c\u2500\u2500 code_and_slurm-scripts\n\u2502   \u251c\u2500\u2500 optuna_mnist.py\n\u2502   \u251c\u2500\u2500 check_best_model.py\n\u2502   \u251c\u2500\u2500 run-optuna-multinode_Turpan.sh\n\u2502   \u251c\u2500\u2500 init_optuna_db.py\n\u2502   \u251c\u2500\u2500 study.db                (fichier SQLite partag\xe9)\n\u251c\u2500\u2500 data/\n\u2502   \u2514\u2500\u2500 MNIST/                  (dataset MNIST)\n\u2514\u2500\u2500 README.txt\n")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"structure-du-r\xe9pertoire"},"Structure du r\xe9pertoire"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Fichier"),(0,r.kt)("th",{parentName:"tr",align:null},"R\xf4le"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"optuna_mnist.py")),(0,r.kt)("td",{parentName:"tr",align:null},"Script principal Optuna (fonction objective + entra\xeenement MNIST)")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"check_best_model.py")),(0,r.kt)("td",{parentName:"tr",align:null},"Lit le meilleur mod\xe8le depuis la base de donn\xe9es")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"run-optuna-multinode-Turpan.sh")),(0,r.kt)("td",{parentName:"tr",align:null},"Script SLURM multi\u2011n\u0153uds utilisant apptainer")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"init_optuna_db.py")),(0,r.kt)("td",{parentName:"tr",align:null},"Cr\xe9e la base de donnes. Code lanc\xe9 aussi par run-optuna-multinode-Turpan.sh")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"study.db")),(0,r.kt)("td",{parentName:"tr",align:null},"Base SQLite contenant les r\xe9sultats (cr\xe9e par le code)")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"data/MNIST")),(0,r.kt)("td",{parentName:"tr",align:null},"Dataset t\xe9l\xe9charg\xe9 automatiquement")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"README.txt")),(0,r.kt)("td",{parentName:"tr",align:null},"Instructions")))),(0,r.kt)("p",null,"Optuna utilise le fichier ",(0,r.kt)("inlineCode",{parentName:"p"},"study.db")," comme base de donn\xe9es distribu\xe9e.",(0,r.kt)("br",{parentName:"p"}),"\n","Tous les workers (t\xe2ches SLURM) \xe9crivent dans cette base."),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"installer-optuna-dans-le-conteneur-turpan"},"Installer Optuna dans le conteneur Turpan"),(0,r.kt)("p",null,"Ouvrir un shell dans le conteneur :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"apptainer shell --bind /tmpdir,/work --nv /work/conteneurs/sessions-interactives/pytorch-24.02-py3-calmip-si.sif\n")),(0,r.kt)("p",null,"Installer Optuna :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"Apptainer> pip install optuna\n")),(0,r.kt)("p",null,"Quitter le conteneur :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Ctrl + d\n")),(0,r.kt)("p",null,"Vous \xeates maintenant pr\xeat \xe0 lancer l\u2019optimisation."),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"fonctionnement-doptuna-sur-turpan-multin\u0153uds"},"Fonctionnement d\u2019Optuna sur Turpan (multi\u2011n\u0153uds)"),(0,r.kt)("p",null,"Optuna fonctionne ainsi :"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"chaque t\xe2che SLURM (chaque GPU typiquement) d\xe9marre un worker,")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"chaque worker charge la m\xeame base de donn\xe9es ",(0,r.kt)("inlineCode",{parentName:"p"},"study.db"),",")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"la m\xe9thode ",(0,r.kt)("inlineCode",{parentName:"p"},"study.optimize()")," demande \xe0 Optuna de cr\xe9er un ",(0,r.kt)("em",{parentName:"p"},"trial"),",")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Optuna r\xe9serve ce trial dans la base de donn\xe9es,")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"votre code entra\xeene un mod\xe8le,")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Optuna \xe9crit le r\xe9sultat dans la base,")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"un autre worker r\xe9cup\xe8re un nouveau trial dans la base,")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"et le processus continue."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Aucun worker ne traite deux fois le m\xeame trial")," le travail se synchronise automatiquement  "))),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"la-fonction-objectivetrial--c\u0153ur-doptuna"},"La fonction ",(0,r.kt)("inlineCode",{parentName:"h2"},"objective(trial)")," \u2014 c\u0153ur d\u2019Optuna"),(0,r.kt)("p",null,"Exemple utilis\xe9 dans l\u2019entra\xeenement MNIST :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'def objective(trial):\n\n    config = {\n        "lr": trial.suggest_float("lr", 1e-4, 5e-3, log=True),\n        "batch_size": trial.suggest_categorical("batch_size", [16, 32, 64, 128]),\n        "conv1_channels": trial.suggest_categorical("conv1_channels", [8, 16, 32, 64]),\n        "conv2_channels": trial.suggest_categorical("conv2_channels", [16, 32, 64, 128]),\n        "kernel1": trial.suggest_categorical("kernel1", [3, 5, 7]),\n        "kernel2": trial.suggest_categorical("kernel2", [3, 5, 7]),\n        "fc_dim": trial.suggest_categorical("fc_dim", [64, 128, 256, 512]),\n        "epochs": trial.suggest_categorical("epochs", [2, 3, 5]),\n        "num_classes": 10\n    }\n\n    loss = train_model(config, trial)\n    return loss\n')),(0,r.kt)("h3",{id:"pourquoi-passer-trial-\xe0-train_model-"},"Pourquoi passer ",(0,r.kt)("inlineCode",{parentName:"h3"},"trial")," \xe0 ",(0,r.kt)("inlineCode",{parentName:"h3"},"train_model()")," ?"),(0,r.kt)("p",null,"Car ",(0,r.kt)("inlineCode",{parentName:"p"},"trial.report()")," et ",(0,r.kt)("inlineCode",{parentName:"p"},"trial.should_prune()")," sont n\xe9cessaires :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"trial.report(epoch_loss, epoch)\n\nif trial.should_prune():\n    raise optuna.TrialPruned()\n")),(0,r.kt)("p",null,"Cela active le ",(0,r.kt)("em",{parentName:"p"},"pruning")," :",(0,r.kt)("br",{parentName:"p"}),"\n","\u2192 arr\xeate t\xf4t les mauvaises configurations \u2192 \xe9conomise du temps GPU"),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"script-sbatch-multin\u0153uds-multigpu"},"Script SBATCH (multi\u2011n\u0153uds, multi\u2011GPU)"),(0,r.kt)("p",null,"Voici la version adapt\xe9e Turpan :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'#!/bin/bash\n#SBATCH --job-name=optuna-mnist\n#SBATCH --output=logs/%A_%a.%t.out\n#SBATCH --error=logs/%A_%a.%t.err\n#SBATCH --nodes=2                 # 2 nodes\n#SBATCH --ntasks-per-node=2       # 2 tasks per node -> 2 GPUs per node\n#SBATCH --gres=gpu:2              # 2 GPUs per node\n#SBATCH --gpus-per-task=1\n#SBATCH --cpus-per-task=4\n#SBATCH --time=00:10:00\n#SBATCH --mem=16G\n\nset -euo pipefail\n\n# ---------- USER CONFIG ----------\nUSER_WORKDIR="${SLURM_SUBMIT_DIR}"        # must be shared across nodes\nCONTAINER=/work/conteneurs/sessions-interactives/pytorch-24.02-py3-calmip-si.sif\nPY_SCRIPT=$USER_WORKDIR/optuna_mnist.py\nSTUDY_DB=sqlite:///study.db\nDB_PATH="$USER_WORKDIR/study.db"\nSTUDY_NAME="mnist_hpo"\nTOTAL_TRIALS=500            # total trials you want to run across all workers\n# -----------------------------------\nINIT_SCRIPT=$USER_WORKDIR/init_optuna_db.py\n\nmkdir -p "$USER_WORKDIR"\nmkdir -p logs\n\n# ======================================================\n#  CREATE DB BEFORE RUNNING THE CODE\n# ======================================================\necho "\ud83d\udfe6 Initializing DB before starting parallel workers..."\n\napptainer exec \\\n    --bind /tmpdir \\\n    "$CONTAINER" \\\n    python "$INIT_SCRIPT" "$STUDY_DB" "$STUDY_NAME"\necho "[SBATCH] DB ready. Launching workers\u2026"\n\n# Ensure $HOME/.local/bin is in PATH for the container\nexport PATH="$HOME/.local/bin:$PATH"\n\necho "SLURM NODELIST: $SLURM_NODELIST"\necho "SLURM_NNODES: $SLURM_NNODES"\necho "SLURM_NTASKS_PER_NODE: $SLURM_NTASKS_PER_NODE"\necho "Total tasks (ntasks): $SLURM_NTASKS"\necho "This job will launch $SLURM_NTASKS tasks (one per GPU)."\n\n# srun will launch the same command once per task (ntasks = nodes * ntasks-per-node)\n# Each task runs a separate Apptainer instance, inside the container the script uses SLURM vars\nsrun --kill-on-bad-exit=1 --ntasks=$SLURM_NTASKS \\\n    apptainer exec --nv \\\n        --bind /tmpdir \\\n        --env PATH="$PATH" \\\n        --env STUDY_DB="/optuna_workdir/$(basename "$STUDY_DB")" \\\n        --env STUDY_NAME="$STUDY_NAME" \\\n        --env TOTAL_TRIALS="$TOTAL_TRIALS" \\\n        "$CONTAINER" \\\n        python "$PY_SCRIPT"\n')),(0,r.kt)("h3",{id:"comment-cela-se-r\xe9partit-"},"Comment cela se r\xe9partit ?"),(0,r.kt)("p",null,"Avec deux n\u0153uds \xd7 deux GPU \u2192 ",(0,r.kt)("strong",{parentName:"p"},"4 workers Optuna en parall\xe8le"),"."),(0,r.kt)("p",null,"Chaque worker traite un trial ind\xe9pendant."),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"r\xe9cup\xe9rer-le-meilleur-mod\xe8le"},"R\xe9cup\xe9rer le meilleur mod\xe8le"),(0,r.kt)("p",null,"Vous pouvez lancer :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"apptainer exec --bind /tmpdir,/work --nv /work/conteneurs/sessions-interactives/pytorch-24.02-py3-calmip-si.sif python check_best_model.py\n")),(0,r.kt)("p",null,"Le fichier :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import optuna\nstudy = optuna.load_study("mnist_hpo", storage="sqlite:///study.db")\nprint(study.best_value)\nprint(study.best_params)\n')),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"algorithmes-doptimisation-avanc\xe9s-dans-optuna"},"Algorithmes d'optimisation avanc\xe9s dans Optuna"),(0,r.kt)("p",null,"Optuna propose plusieurs moteurs de recherche d\u2019hyperparam\xe8tres :"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Algorithme"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"),(0,r.kt)("th",{parentName:"tr",align:null},"Recommand\xe9"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"TPE (par d\xe9faut)")),(0,r.kt)("td",{parentName:"tr",align:null},"Tr\xe8s efficace, adaptatif"),(0,r.kt)("td",{parentName:"tr",align:null},"Recommand\xe9")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"RandomSearch")),(0,r.kt)("td",{parentName:"tr",align:null},"Basique mais robuste"),(0,r.kt)("td",{parentName:"tr",align:null},"petites exp\xe9riences")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"GridSearch")),(0,r.kt)("td",{parentName:"tr",align:null},"exhaustive"),(0,r.kt)("td",{parentName:"tr",align:null},"espaces petits")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"CMA\u2011ES")),(0,r.kt)("td",{parentName:"tr",align:null},"optimisation \xe9volutive"),(0,r.kt)("td",{parentName:"tr",align:null},"grands espaces continus")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"BruteForceSampler")),(0,r.kt)("td",{parentName:"tr",align:null},"debug"),(0,r.kt)("td",{parentName:"tr",align:null},"jamais en production")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"NSGA\u2011II")),(0,r.kt)("td",{parentName:"tr",align:null},"optimisation multi\u2011objectifs"),(0,r.kt)("td",{parentName:"tr",align:null},"probl\xe8mes scientifiques")))),(0,r.kt)("h3",{id:"exemple-tpe-par-d\xe9faut"},"Exemple TPE (par d\xe9faut)"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'study = optuna.create_study(direction="minimize", sampler=optuna.samplers.TPESampler())\n')),(0,r.kt)("h3",{id:"exemple-cmaes"},"Exemple CMA\u2011ES"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from optuna.samplers import CmaEsSampler\nstudy = optuna.create_study(sampler=CmaEsSampler())\n")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"visualisations-optuna"},"Visualisations Optuna"),(0,r.kt)("p",null,"Optuna permet de g\xe9n\xe9rer automatiquement des graphiques :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"optuna.visualization.plot_optimization_history(study)\noptuna.visualization.plot_param_importances(study)\noptuna.visualization.plot_parallel_coordinate(study)\n")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"adapter-lexemple-\xe0-des-mod\xe8les-plus-grands-llm"},"Adapter l\u2019exemple \xe0 des mod\xe8les plus grands (LLM)"),(0,r.kt)("p",null,"Il suffit de remplacer le mod\xe8le MNIST :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from transformers import T5ForConditionalGeneration, T5Config\n\ndef build_model(config):\n    tconf = T5Config(\n        d_model=config["hidden_size"],\n        num_heads=config["num_heads"],\n        num_layers=config["num_layers"]\n    )\n    return T5ForConditionalGeneration(tconf)\n')),(0,r.kt)("p",null,"Et d\xe9finir un espace :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'"hidden_size": trial.suggest_categorical([512, 768, 1024]),\n"num_layers": trial.suggest_int("num_layers", 4, 24),\n"num_heads": trial.suggest_categorical([8, 12, 16]),\n"lr": trial.suggest_float(1e-6, 1e-4, log=True),\n')),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"lancer-le-job"},"Lancer le job"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"sbatch run-optuna-multinode-Turpan.sh\n")),(0,r.kt)("p",null,"Suivre la file :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"squeue --me\n")),(0,r.kt)("p",null,"Voir quels GPU sont utilis\xe9s :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"placement --checkme\n")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"scalabilit\xe9-attendue-sur-turpan"},"Scalabilit\xe9 attendue sur Turpan"),(0,r.kt)("p",null,"Si vous lancez 500 trials avec 4 GPU :"),(0,r.kt)("p",null,"\u2192 4 trials simultan\xe9s",(0,r.kt)("br",{parentName:"p"}),"\n","\u2192 Optuna envoie un nouveau trial d\xe8s qu\u2019un GPU se lib\xe8re",(0,r.kt)("br",{parentName:"p"}),"\n","\u2192 Temps total \u2248 (500 / 4) \xd7 dur\xe9e d\u2019un entra\xeenement"),(0,r.kt)("p",null,"Avec 8 GPU \u2192 8 trials simultan\xe9s",(0,r.kt)("br",{parentName:"p"}),"\n","Avec 16 GPU \u2192 16 trials simultan\xe9s"),(0,r.kt)("p",null,"Optuna scale bien tant qu\u2019il y a des trials \xe0 lancer."),(0,r.kt)("p",null,"Ce document fournit un exemple complet utilisant MNIST, mais le sch\xe9ma peut \xeatre \xe9tendu \xe0 des mod\xe8les plus complexes comme des CNN plus profonds ou des mod\xe8les transformers."),(0,r.kt)("hr",null))}d.isMDXComponent=!0}}]);