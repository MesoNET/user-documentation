"use strict";(self.webpackChunkmesodocs=self.webpackChunkmesodocs||[]).push([[5387],{4137:(e,t,n)=>{n.d(t,{Zo:()=>o,kt:()=>h});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},l=Object.keys(e);for(r=0;r<l.length;r++)n=l[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(r=0;r<l.length;r++)n=l[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var u=r.createContext({}),p=function(e){var t=r.useContext(u),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},o=function(e){var t=p(e.components);return r.createElement(u.Provider,{value:t},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,l=e.originalType,u=e.parentName,o=s(e,["components","mdxType","originalType","parentName"]),c=p(n),m=a,h=c["".concat(u,".").concat(m)]||c[m]||d[m]||l;return n?r.createElement(h,i(i({ref:t},o),{},{components:n})):r.createElement(h,i({ref:t},o))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var l=n.length,i=new Array(l);i[0]=m;var s={};for(var u in t)hasOwnProperty.call(t,u)&&(s[u]=t[u]);s.originalType=e,s[c]="string"==typeof e?e:a,i[1]=s;for(var p=2;p<l;p++)i[p]=n[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},3930:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>u,contentTitle:()=>i,default:()=>d,frontMatter:()=>l,metadata:()=>s,toc:()=>p});var r=n(7462),a=(n(7294),n(4137));const l={},i="Ray Tune",s={unversionedId:"arch_exp/turpan/ressources_ia/HPO/ray_tune",id:"arch_exp/turpan/ressources_ia/HPO/ray_tune",title:"Ray Tune",description:"Ray Tune est un framework \xe9volutif d'optimisation d'hyperparam\xe8tres qui facilite l'ex\xe9cution de nombreux entra\xeenements en parall\xe8le. Chaque exp\xe9rience, appel\xe9e trial, entra\xeene un mod\xe8le en utilisant une combinaison diff\xe9rente d'hyperparam\xe8tres \u2014 par exemple le taux d'apprentissage, la taille de lot, le nombre de couches ou les param\xe8tres de l'optimiseur. Plut\xf4t que de lancer des dizaines d'exp\xe9riences \xe0 la main, Ray Tune automatise le processus et r\xe9partit le travail sur l'ensemble des ressources de calcul disponibles.",source:"@site/docs/arch_exp/turpan/ressources_ia/HPO/ray_tune.md",sourceDirName:"arch_exp/turpan/ressources_ia/HPO",slug:"/arch_exp/turpan/ressources_ia/HPO/ray_tune",permalink:"/documentation/user-documentation/arch_exp/turpan/ressources_ia/HPO/ray_tune",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Optuna",permalink:"/documentation/user-documentation/arch_exp/turpan/ressources_ia/HPO/optuna"},next:{title:"Flow Matching",permalink:"/documentation/user-documentation/arch_exp/turpan/ressources_ia/flow_matching"}},u={},p=[{value:"Ressources sur cette page",id:"ressources-sur-cette-page",level:2},{value:"Copier l&#39;exemple de code",id:"copier-lexemple-de-code",level:2},{value:"Installer ray dans l&#39;environement",id:"installer-ray-dans-lenvironement",level:3},{value:"Structure du r\xe9pertoire",id:"structure-du-r\xe9pertoire",level:2},{value:"Description des fichiers",id:"description-des-fichiers",level:3},{value:"R\xf4le des fichiers : comment Ray Tune interagit avec le code d\u2019entra\xeenement",id:"r\xf4le-des-fichiers--comment-ray-tune-interagit-avec-le-code-dentra\xeenement",level:4},{value:"Script SLURM (sbatch)",id:"script-slurm-sbatch",level:2},{value:"Concepts cl\xe9s",id:"concepts-cl\xe9s",level:3},{value:"Script principal Ray Tune",id:"script-principal-ray-tune",level:2},{value:"Initialiser Ray dans SLURM",id:"initialiser-ray-dans-slurm",level:3},{value:"Attribution des ressources",id:"attribution-des-ressources",level:3},{value:"Espace de recherche Ray Tune (modifiable)",id:"espace-de-recherche-ray-tune-modifiable",level:2},{value:"Comment Ray collecte les r\xe9sultats",id:"comment-ray-collecte-les-r\xe9sultats",level:3},{value:"Mod\xe8le MNIST dynamique",id:"mod\xe8le-mnist-dynamique",level:2},{value:"Adapter pour des exp\xe9riences LLM",id:"adapter-pour-des-exp\xe9riences-llm",level:2},{value:"Lancer le job",id:"lancer-le-job",level:2},{value:"Utiliser des algorithmes de recherche avanc\xe9s (BOHB, HEBO, Optuna, BayesOpt)",id:"utiliser-des-algorithmes-de-recherche-avanc\xe9s-bohb-hebo-optuna-bayesopt",level:2}],o={toc:p},c="wrapper";function d(e){let{components:t,...n}=e;return(0,a.kt)(c,(0,r.Z)({},o,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"ray-tune"},"Ray Tune"),(0,a.kt)("p",null,"Ray Tune est un framework \xe9volutif d'optimisation d'hyperparam\xe8tres qui facilite l'ex\xe9cution de nombreux entra\xeenements en parall\xe8le. Chaque exp\xe9rience, appel\xe9e ",(0,a.kt)("em",{parentName:"p"},"trial"),", entra\xeene un mod\xe8le en utilisant une combinaison diff\xe9rente d'hyperparam\xe8tres \u2014 par exemple le taux d'apprentissage, la taille de lot, le nombre de couches ou les param\xe8tres de l'optimiseur. Plut\xf4t que de lancer des dizaines d'exp\xe9riences \xe0 la main, Ray Tune automatise le processus et r\xe9partit le travail sur l'ensemble des ressources de calcul disponibles."),(0,a.kt)("p",null,"L'un des points forts de Ray Tune est son support d'une large palette d'algorithmes d'optimisation modernes. Au-del\xe0 de la recherche al\xe9atoire ou de la recherche sur grille, Ray Tune peut adapter automatiquement l'\xe9chantillonnage des hyperparam\xe8tres en utilisant des m\xe9thodes telles que BOHB, HEBO, Optuna, l'optimisation bay\xe9sienne, HyperBand ou ASHA. Ces algorithmes tirent parti des r\xe9sultats des essais pr\xe9c\xe9dents et concentrent la recherche sur les r\xe9gions les plus prometteuses, ce qui permet d'obtenir de meilleurs hyperparam\xe8tres avec moins d'exp\xe9riences au total."),(0,a.kt)("p",null,"Ce document explique comment lancer Ray Tune sur le cluster Turpan en utilisant des scripts SLURM pour deux et huit GPU. Il d\xe9crit aussi comment modifier la configuration des hyperparam\xe8tres, comment basculer entre diff\xe9rents algorithmes de recherche, et comment le script d'entra\xeenement construit dynamiquement l'architecture du r\xe9seau de neurones \xe0 partir des hyperparam\xe8tres choisis pour chaque essai. Enfin, il indique comment adapter l'exemple \xe0 des mod\xe8les plus complexes, comme des LLM bas\xe9s sur des transformeurs."),(0,a.kt)("hr",null),(0,a.kt)("h2",{id:"ressources-sur-cette-page"},"Ressources sur cette page"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#copier-lexemple-de-code"},"Copier l'exemple de code et mettre en place l'environement"),"  "),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#structure-du-r%C3%A9pertoire"},"Structure du r\xe9pertoire"),"  "),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#script-slurm-sbatch"},"Script SLURM (sbatch)"),"  "),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#script-principal-ray-tune"},"Script principal Ray Tune"),"  "),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#espace-de-recherche-ray-tune-modifiable"},"Espace de recherche Ray Tune"),"  "),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#mod%C3%A8le-mnist-dynamique"},"Mod\xe8le MNIST dynamique"),"  "),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#adapter-pour-des-exp%C3%A9riences-llm"},"Adapter pour des exp\xe9riences LLM"),"  "),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#lancer-le-job"},"Lancer le job"),"  "),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#utiliser-des-algorithmes-de-recherche-avanc%C3%A9s-bohb-hebo-optuna-bayesopt"},"Algorithmes de recherche avanc\xe9s"),"  ")),(0,a.kt)("hr",null),(0,a.kt)("h2",{id:"copier-lexemple-de-code"},"Copier l'exemple de code"),(0,a.kt)("p",null,"Tous les scripts d'exemple Ray Tune et les lanceurs SLURM sont disponibles sur Turpan et peuvent \xeatre copi\xe9s directement depuis :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"/work/shares/IA-Tests/ray_tune.tar.gz\n")),(0,a.kt)("p",null,"Pour l'extraire dans votre r\xe9pertoire :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"tar xvf /work/shares/IA-Tests/ray_tune.tar.gz\n")),(0,a.kt)("p",null,"Cela cr\xe9era un r\xe9pertoire nomm\xe9 ",(0,a.kt)("inlineCode",{parentName:"p"},"ray_tune/"),"."),(0,a.kt)("h3",{id:"installer-ray-dans-lenvironement"},"Installer ray dans l'environement"),(0,a.kt)("p",null,"Le seul paquet n\xe9cessaire est ray.\nPour l\u2019installer, il suffit d\u2019ouvrir le conteneur en mode shell :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"apptainer shell --bind /tmpdir,/work --nv /work/conteneurs/sessions-interactives/pytorch-24.02-py3-calmip-si.sif\n")),(0,a.kt)("p",null,"Ensuite, \xe0 l\u2019int\xe9rieur du conteneur, on installe Ray avec pip :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"Apptainer> pip install ray\n")),(0,a.kt)("p",null,"Pour sortir du conteneur :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"Crlt + d // pour sortir du conteneur \n")),(0,a.kt)("p",null,"A ce moment l\xe0 tout est pret pour ",(0,a.kt)("a",{parentName:"p",href:"#lancer-le-job"},"lancer le calcul")),(0,a.kt)("hr",null),(0,a.kt)("h2",{id:"structure-du-r\xe9pertoire"},"Structure du r\xe9pertoire"),(0,a.kt)("p",null,"Apr\xe8s extraction vous devriez obtenir :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"ray_tune/\n\u251c\u2500\u2500 code_and_slurm-scripts\n\u2502   \u251c\u2500\u2500 mnist_ddp.py\n\u2502   \u251c\u2500\u2500 ray_tune.py\n\u2502   \u251c\u2500\u2500 run-ray_tune_on_2gpus_Turpan.sh\n\u251c\u2500\u2500 data\n\u2502   \u2514\u2500\u2500 MNIST/               (dataset MNIST t\xe9l\xe9charg\xe9)\n\u2514\u2500\u2500 README.txt\n")),(0,a.kt)("h3",{id:"description-des-fichiers"},"Description des fichiers"),(0,a.kt)("table",null,(0,a.kt)("thead",{parentName:"table"},(0,a.kt)("tr",{parentName:"thead"},(0,a.kt)("th",{parentName:"tr",align:null},"Fichier"),(0,a.kt)("th",{parentName:"tr",align:null},"Description"))),(0,a.kt)("tbody",{parentName:"table"},(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"mnist_ddp.py")),(0,a.kt)("td",{parentName:"tr",align:null},"Script d'entra\xeenement utilisant PyTorch")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"ray_tune.py")),(0,a.kt)("td",{parentName:"tr",align:null},"Script principal Ray Tune pour l'HPO")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"run-ray_tune_on_2gpus_Turpan.sh")),(0,a.kt)("td",{parentName:"tr",align:null},"Script SLURM pour lancer Ray Tune sur 2 GPU")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"data/MNIST")),(0,a.kt)("td",{parentName:"tr",align:null},"Dataset MNIST (t\xe9l\xe9charg\xe9 automatiquement si manquant)")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"README.txt")),(0,a.kt)("td",{parentName:"tr",align:null},"Instructions et notes")))),(0,a.kt)("h4",{id:"r\xf4le-des-fichiers--comment-ray-tune-interagit-avec-le-code-dentra\xeenement"},"R\xf4le des fichiers : comment Ray Tune interagit avec le code d\u2019entra\xeenement"),(0,a.kt)("p",null,"Le fichier ray_tune.py agit comme une couche au-dessus du script d\u2019entra\xeenement :"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"C\u2019est lui qui d\xe9finit l\u2019espace d\u2019hyperparam\xe8tres \xe0 explorer (learning rate, batch size, nombre de couches, etc.)."),(0,a.kt)("li",{parentName:"ul"},"Il choisit comment explorer cet espace : al\xe9atoire, grid search, BOHB, Optuna, BayesOpt, etc."),(0,a.kt)("li",{parentName:"ul"},"Il cr\xe9e et lance chaque essai d\u2019entra\xeenement (trial) en appelant votre fonction d\u2019entra\xeenement dans mnist_ddp.py."),(0,a.kt)("li",{parentName:"ul"},"Il attribue les ressources (nombre de GPU/CPU par essai)."),(0,a.kt)("li",{parentName:"ul"},"Il r\xe9cup\xe8re les m\xe9triques via tune.report() et les utilise pour guider la recherche.")),(0,a.kt)("h2",{id:"script-slurm-sbatch"},"Script SLURM (sbatch)"),(0,a.kt)("p",null,"Exemple de fichier sbatch utilis\xe9 pour lancer Ray Tune sur ",(0,a.kt)("strong",{parentName:"p"},"4 n\u0153uds"),", chacun avec ",(0,a.kt)("strong",{parentName:"p"},"2 GPU"),", en utilisant ",(0,a.kt)("inlineCode",{parentName:"p"},"srun")," + ",(0,a.kt)("inlineCode",{parentName:"p"},"apptainer")," :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"#!/bin/bash\n#SBATCH --job-name=benchmark\n#SBATCH -N 4\n#SBATCH --ntasks=4\n#SBATCH --cpus-per-task=40\n#SBATCH --mem=100G\n#SBATCH --time=40\n#SBATCH --gres=gpu:2\n\nsrun apptainer exec --bind /tmpdir,/work --nv /work/conteneurs/sessions-interactives/pytorch-24.02-py3-calmip-si.sif python3 ray_tune.py\n")),(0,a.kt)("h3",{id:"concepts-cl\xe9s"},"Concepts cl\xe9s"),(0,a.kt)("p",null,"Une t\xe2che Ray correspond \xe0 un processus lanc\xe9 par Ray. Avec ",(0,a.kt)("inlineCode",{parentName:"p"},"--ntasks=4")," et ",(0,a.kt)("inlineCode",{parentName:"p"},"--gres=gpu:2"),", vous avez 4 workers Ray et chaque worker voit 2 GPU. Ray d\xe9tecte automatiquement les GPU r\xe9serv\xe9s via ",(0,a.kt)("inlineCode",{parentName:"p"},"ray.cluster_resources()")," et lance des ",(0,a.kt)("em",{parentName:"p"},"trials")," en parall\xe8le tant que des GPU libres existent."),(0,a.kt)("hr",null),(0,a.kt)("h2",{id:"script-principal-ray-tune"},"Script principal Ray Tune"),(0,a.kt)("p",null,"Le script ",(0,a.kt)("inlineCode",{parentName:"p"},"ray_tune.py")," initialise Ray, d\xe9finit l'espace de recherche, le scheduler et soumet les essais."),(0,a.kt)("h3",{id:"initialiser-ray-dans-slurm"},"Initialiser Ray dans SLURM"),(0,a.kt)("p",null,"Ray est lanc\xe9 localement dans le job :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'ray.init(\n    num_cpus=max(1, int(os.environ.get("SLURM_CPUS_PER_TASK", "40"))),\n    include_dashboard=False,\n    _system_config={"enable_metrics_collection": False}\n)\n')),(0,a.kt)("h3",{id:"attribution-des-ressources"},"Attribution des ressources"),(0,a.kt)("p",null,"Chaque essai utilise par exemple :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'tune.with_resources(original_main, resources={"cpu": 4, "gpu": 1})\n')),(0,a.kt)("p",null,"Cela signifie que chaque ",(0,a.kt)("em",{parentName:"p"},"trial")," consomme 1 GPU. Si chaque n\u0153ud offre 2 GPU \u2192 2 trials simultan\xe9s par noeud."),(0,a.kt)("p",null,"Si vous voulez qu'un ",(0,a.kt)("em",{parentName:"p"},"trial")," utilise plusieurs GPU, changez ",(0,a.kt)("inlineCode",{parentName:"p"},'"gpu": 2')," et adaptez le code d'entra\xeenement pour utiliser ",(0,a.kt)("inlineCode",{parentName:"p"},"DistributedDataParallel")," ou un sch\xe9ma multi-GPU."),(0,a.kt)("hr",null),(0,a.kt)("h2",{id:"espace-de-recherche-ray-tune-modifiable"},"Espace de recherche Ray Tune (modifiable)"),(0,a.kt)("p",null,"Exemple d'espace utilis\xe9 :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'config = {\n    "lr": tune.loguniform(1e-5, 5e-3),\n    "batch_size": tune.choice([16, 32, 64, 128]),\n    "optimizer": tune.choice(["adam", "sgd", "adamw"]),\n    "weight_decay": tune.uniform(0.0, 0.1),\n\n    "conv1_channels": tune.choice([8, 16, 32, 64]),\n    "conv2_channels": tune.choice([16, 32, 64, 128]),\n    "conv3_channels": tune.choice([0, 16, 32, 64, 128]),\n\n    "kernel1": tune.choice([3, 5, 7]),\n    "kernel2": tune.choice([3, 5, 7]),\n    "kernel3": tune.choice([3, 5, 7]),\n\n    "activation": tune.choice(["relu", "gelu", "silu"]),\n    "dropout": tune.uniform(0.0, 0.5),\n\n    "fc_dim": tune.choice([64, 128, 256, 512]),\n\n    "scheduler": tune.choice(["none", "cosine", "step", "onecycle"]),\n    "step_size": tune.choice([10, 20, 30]),\n    "gamma": tune.uniform(0.1, 0.9),\n\n    "epochs": tune.choice([2, 3, 5]),\n    "num_classes": 10,\n}\n')),(0,a.kt)("p",null,"Adaptez ces param\xe8tres pour \xe9largir ou restreindre l'espace de recherche selon vos besoins."),(0,a.kt)("hr",null),(0,a.kt)("h3",{id:"comment-ray-collecte-les-r\xe9sultats"},"Comment Ray collecte les r\xe9sultats"),(0,a.kt)("p",null,"\xc0 la fin d'une \xe9poque, le script d'entra\xeenement appelle :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'tune.report({"loss": loss_sum / len(train_loader)})\n')),(0,a.kt)("p",null,"Les logs Ray et le stdout s'\xe9crivent dans le fichier SLURM (p.ex. ",(0,a.kt)("inlineCode",{parentName:"p"},"slurm-<JOBID>.out"),"), que vous pouvez consulter avec ",(0,a.kt)("inlineCode",{parentName:"p"},"cat"),"."),(0,a.kt)("hr",null),(0,a.kt)("h2",{id:"mod\xe8le-mnist-dynamique"},"Mod\xe8le MNIST dynamique"),(0,a.kt)("p",null,"Dans ",(0,a.kt)("inlineCode",{parentName:"p"},"mnist_ddp.py"),", le mod\xe8le se construit dynamiquement \xe0 partir de la configuration Ray :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'self.layer1 = nn.Sequential(\n    nn.Conv2d(1, config["conv1_channels"], config["kernel1"], padding=config["kernel1"]//2),\n    nn.BatchNorm2d(config["conv1_channels"]),\n    nn.ReLU(),\n    nn.MaxPool2d(2)\n)\n')),(0,a.kt)("p",null,"Cette approche permet :"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"d'ajouter/supprimer des couches,"),(0,a.kt)("li",{parentName:"ul"},"de tester diff\xe9rentes largeurs de canaux,"),(0,a.kt)("li",{parentName:"ul"},"de changer les fonctions d'activation,"),(0,a.kt)("li",{parentName:"ul"},"d'activer le dropout,"),(0,a.kt)("li",{parentName:"ul"},"de varier la taille des noyaux.")),(0,a.kt)("p",null,"Tout cela est construit automatiquement pour chaque ",(0,a.kt)("em",{parentName:"p"},"trial"),"."),(0,a.kt)("hr",null),(0,a.kt)("h2",{id:"adapter-pour-des-exp\xe9riences-llm"},"Adapter pour des exp\xe9riences LLM"),(0,a.kt)("p",null,"Pour passer de MNIST \xe0 un mod\xe8le T5 (ou autre LLM), remplacez la partie mod\xe8le par une construction T5 :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'from transformers import T5Config, T5ForConditionalGeneration\n\nconfig_llm = T5Config(\n    d_model=config["hidden_size"],\n    num_heads=config["num_heads"],\n    num_layers=config["num_layers"]\n)\n\nmodel = T5ForConditionalGeneration(config_llm)\n')),(0,a.kt)("p",null,"D\xe9clarez les hyperparam\xe8tres pertinents dans l'espace Ray, par exemple :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'"hidden_size": tune.choice([512, 768, 1024]),\n"num_heads": tune.choice([8, 12, 16]),\n"num_layers": tune.choice([4, 8, 12]),\n')),(0,a.kt)("p",null,"Supprimez les parties li\xe9es \xe0 MNIST (dataset, transformations) et adaptez le pipeline d'entra\xeenement."),(0,a.kt)("hr",null),(0,a.kt)("h2",{id:"lancer-le-job"},"Lancer le job"),(0,a.kt)("p",null,"Dans ",(0,a.kt)("inlineCode",{parentName:"p"},"code_and_slurm-scripts")," il y a un exemple pr\xeat \xe0 \xeatre lanc\xe9 ",(0,a.kt)("inlineCode",{parentName:"p"},"run-ray_tune_on_2gpus_Turpan.sh"),".\nPour les lancer il suffit de :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"sbatch run-ray_tune_on_2gpus_Turpan.sh\n")),(0,a.kt)("p",null,"Pour surveillez la file d'attente :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"squeue --me\n")),(0,a.kt)("p",null,"V\xe9rifiez l'utilisation des GPU une fois le job est en RUNNING (commande interne au cluster) :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"placement --checkme\n")),(0,a.kt)("hr",null),(0,a.kt)("h2",{id:"utiliser-des-algorithmes-de-recherche-avanc\xe9s-bohb-hebo-optuna-bayesopt"},"Utiliser des algorithmes de recherche avanc\xe9s (BOHB, HEBO, Optuna, BayesOpt)"),(0,a.kt)("p",null,"Ray Tune permet de remplacer la recherche al\xe9atoire par des algorithmes adaptatifs. Ajoutez un ",(0,a.kt)("em",{parentName:"p"},"search_alg")," au ",(0,a.kt)("inlineCode",{parentName:"p"},"Tuner")," :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'from ray import tune\nfrom ray.tune.search.bohb import TuneBOHB\nfrom ray.tune.search.optuna import OptunaSearch\nfrom ray.tune.search.hebo import HEBOSearch\nfrom ray.tune.search.bayesopt import BayesOptSearch\n\nsearch_alg = OptunaSearch()  # <-- choisissez un algo\n\ntuner = tune.Tuner(\n    train_fn,\n    param_space=config,\n    tune_config=tune.TuneConfig(\n        metric="loss",\n        mode="min",\n        num_samples=50,        # nombre total d\'essais\n        search_alg=search_alg, # l\'algorithme d\'optimisation\n        max_concurrent_trials=2,\n    ),\n)\ntuner.fit()\n')),(0,a.kt)("p",null,'Chaque algorithme a ses forces : Optuna est robuste et populaire, HEBO est efficace pour certains espaces complexes, BOHB combine bande passante et optimisation bay\xe9sienne pour \xeatre efficace en budget restreint. Le "meilleur" d\xe9pend du probl\xe8me et du budget : essayez plusieurs algos.'),(0,a.kt)("hr",null))}d.isMDXComponent=!0}}]);