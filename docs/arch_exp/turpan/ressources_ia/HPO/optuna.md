# Optuna

Optuna est une biblioth√®que d‚Äôoptimisation d‚Äôhyperparam√®tres moderne, efficace et tr√®s flexible. Elle permet d‚Äôexplorer automatiquement un espace d‚Äôhyperparam√®tres, d‚Äôutiliser des algorithmes avanc√©s comme TPE, CMA-ES ou la recherche par grille, et d‚Äôex√©cuter de nombreux essais (¬´ trials ¬ª) en parall√®le.  
Contrairement √† Ray Tune, qui fonctionne bien sur un seul n≈ìud, **Optuna supporte naturellement les environnements multi‚Äën≈ìuds sur Turpan**, via une base de donn√©es partag√©e SQLite que chaque worker met √† jour. Cela permet de lancer des centaines de trials en parall√®le sur plusieurs GPU et plusieurs n≈ìuds.

Ce document explique comment utiliser Optuna sur Turpan :  
- [copier les fichiers d‚Äôexemple](#copier-lexemple-optuna)
- [Structure du r√©pertoire](#structure-du-r√©pertoire)
- [installer Optuna dans le conteneur](#installer-optuna-dans-le-conteneur-turpan)
- [fonctionnement d‚ÄôOptuna sur Turpan (multi‚Äën≈ìuds)](#fonctionnement-doptuna-sur-turpan-multin≈ìuds)
- [√©crire votre fonction `objective(trial)` dynamique](#la-fonction-objectivetrial--c≈ìur-doptuna)
- [Script SBATCH (multi‚Äën≈ìuds, multi‚ÄëGPU)](#script-sbatch-multin≈ìuds-multigpu)  
- [r√©cup√©rer le meilleur mod√®le](#r√©cup√©rer-le-meilleur-mod√®le) 
- [Algorithmes d'optimisation avanc√©s dans Optuna](#algorithmes-doptimisation-avanc√©s-dans-optuna) 
- [Visualisations Optuna](#visualisations-optuna)
- [Adapter l‚Äôexemple √† des mod√®les plus grands (LLM)](#adapter-lexemple-√†-des-mod√®les-plus-grands-llm)
- [Lancer le job](#lancer-le-job)
- [Scalabilit√© attendue sur Turpan](#scalabilit√©-attendue-sur-turpan)

Toute la documentation est adapt√©e exactement √† l‚Äôexemple que nous avons mis en place pour Turpan.

---

##  Copier l'exemple Optuna

Les scripts d‚Äôexemple Optuna se trouvent dans :

```
/work/shares/IA-Tests/optuna.tar.gz
```

Extraire dans votre espace :

```bash
tar xvf /work/shares/IA-Tests/optuna.tar.gz
```

Le r√©pertoire suivant sera cr√©√© :

```
optuna/
‚îú‚îÄ‚îÄ code_and_slurm-scripts
‚îÇ   ‚îú‚îÄ‚îÄ optuna_mnist.py
‚îÇ   ‚îú‚îÄ‚îÄ check_best_model.py
‚îÇ   ‚îú‚îÄ‚îÄ run-optuna-multinode_Turpan.sh
‚îÇ   ‚îú‚îÄ‚îÄ init_optuna_db.py
‚îÇ   ‚îú‚îÄ‚îÄ study.db                (fichier SQLite partag√©)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ MNIST/                  (dataset MNIST)
‚îî‚îÄ‚îÄ README.txt
```

---

##  Structure du r√©pertoire

| Fichier | R√¥le |
|--------|------|
| `optuna_mnist.py` | Script principal Optuna (fonction objective + entra√Ænement MNIST) |
| `check_best_model.py` | Lit le meilleur mod√®le depuis la base de donn√©es |
| `run-optuna-multinode-Turpan.sh` | Script SLURM multi‚Äën≈ìuds utilisant apptainer |
| `init_optuna_db.py` | Cr√©e la base de donnes. Code lanc√© aussi par run-optuna-multinode-Turpan.sh |
| `study.db` | Base SQLite contenant les r√©sultats (cr√©e par le code) |
| `data/MNIST` | Dataset t√©l√©charg√© automatiquement |
| `README.txt` | Instructions |

Optuna utilise le fichier `study.db` comme base de donn√©es distribu√©e.  
Tous les workers (t√¢ches SLURM) √©crivent dans cette base.

---

##  Installer Optuna dans le conteneur Turpan

Ouvrir un shell dans le conteneur :

```bash
apptainer shell --bind /tmpdir,/work --nv /work/conteneurs/sessions-interactives/pytorch-24.02-py3-calmip-si.sif
```

Installer Optuna :

```bash
Apptainer> pip install optuna
```

Quitter le conteneur :

```
Ctrl + d
```

Vous √™tes maintenant pr√™t √† lancer l‚Äôoptimisation.

---

##  Fonctionnement d‚ÄôOptuna sur Turpan (multi‚Äën≈ìuds)

Optuna fonctionne ainsi :

- chaque t√¢che SLURM (chaque GPU typiquement) d√©marre un worker,
- chaque worker charge la m√™me base de donn√©es `study.db`,
- la m√©thode `study.optimize()` demande √† Optuna de cr√©er un *trial*,
- Optuna r√©serve ce trial dans la base de donn√©es,
- votre code entra√Æne un mod√®le,
- Optuna √©crit le r√©sultat dans la base,
- un autre worker r√©cup√®re un nouveau trial dans la base,
- et le processus continue.

 **Aucun worker ne traite deux fois le m√™me trial** le travail se synchronise automatiquement  

---

##  La fonction `objective(trial)` ‚Äî c≈ìur d‚ÄôOptuna

Exemple utilis√© dans l‚Äôentra√Ænement MNIST :

```python
def objective(trial):

    config = {
        "lr": trial.suggest_float("lr", 1e-4, 5e-3, log=True),
        "batch_size": trial.suggest_categorical("batch_size", [16, 32, 64, 128]),
        "conv1_channels": trial.suggest_categorical("conv1_channels", [8, 16, 32, 64]),
        "conv2_channels": trial.suggest_categorical("conv2_channels", [16, 32, 64, 128]),
        "kernel1": trial.suggest_categorical("kernel1", [3, 5, 7]),
        "kernel2": trial.suggest_categorical("kernel2", [3, 5, 7]),
        "fc_dim": trial.suggest_categorical("fc_dim", [64, 128, 256, 512]),
        "epochs": trial.suggest_categorical("epochs", [2, 3, 5]),
        "num_classes": 10
    }

    loss = train_model(config, trial)
    return loss
```

### Pourquoi passer `trial` √† `train_model()` ?

Car `trial.report()` et `trial.should_prune()` sont n√©cessaires :

```python
trial.report(epoch_loss, epoch)

if trial.should_prune():
    raise optuna.TrialPruned()
```

Cela active le *pruning* :  
‚Üí arr√™te t√¥t les mauvaises configurations ‚Üí √©conomise du temps GPU

---

##  Script SBATCH (multi‚Äën≈ìuds, multi‚ÄëGPU)

Voici la version adapt√©e Turpan :

```bash
#!/bin/bash
#SBATCH --job-name=optuna-mnist
#SBATCH --output=logs/%A_%a.%t.out
#SBATCH --error=logs/%A_%a.%t.err
#SBATCH --nodes=2                 # 2 nodes
#SBATCH --ntasks-per-node=2       # 2 tasks per node -> 2 GPUs per node
#SBATCH --gres=gpu:2              # 2 GPUs per node
#SBATCH --gpus-per-task=1
#SBATCH --cpus-per-task=4
#SBATCH --time=00:10:00
#SBATCH --mem=16G

set -euo pipefail

# ---------- USER CONFIG ----------
USER_WORKDIR="${SLURM_SUBMIT_DIR}"        # must be shared across nodes
CONTAINER=/work/conteneurs/sessions-interactives/pytorch-24.02-py3-calmip-si.sif
PY_SCRIPT=$USER_WORKDIR/optuna_mnist.py
STUDY_DB=sqlite:///study.db
DB_PATH="$USER_WORKDIR/study.db"
STUDY_NAME="mnist_hpo"
TOTAL_TRIALS=500            # total trials you want to run across all workers
# -----------------------------------
INIT_SCRIPT=$USER_WORKDIR/init_optuna_db.py

mkdir -p "$USER_WORKDIR"
mkdir -p logs

# ======================================================
#  CREATE DB BEFORE RUNNING THE CODE
# ======================================================
echo "üü¶ Initializing DB before starting parallel workers..."

apptainer exec \
    --bind /tmpdir \
    "$CONTAINER" \
    python "$INIT_SCRIPT" "$STUDY_DB" "$STUDY_NAME"
echo "[SBATCH] DB ready. Launching workers‚Ä¶"

# Ensure $HOME/.local/bin is in PATH for the container
export PATH="$HOME/.local/bin:$PATH"

echo "SLURM NODELIST: $SLURM_NODELIST"
echo "SLURM_NNODES: $SLURM_NNODES"
echo "SLURM_NTASKS_PER_NODE: $SLURM_NTASKS_PER_NODE"
echo "Total tasks (ntasks): $SLURM_NTASKS"
echo "This job will launch $SLURM_NTASKS tasks (one per GPU)."

# srun will launch the same command once per task (ntasks = nodes * ntasks-per-node)
# Each task runs a separate Apptainer instance, inside the container the script uses SLURM vars
srun --kill-on-bad-exit=1 --ntasks=$SLURM_NTASKS \
    apptainer exec --nv \
        --bind /tmpdir \
        --env PATH="$PATH" \
        --env STUDY_DB="/optuna_workdir/$(basename "$STUDY_DB")" \
        --env STUDY_NAME="$STUDY_NAME" \
        --env TOTAL_TRIALS="$TOTAL_TRIALS" \
        "$CONTAINER" \
        python "$PY_SCRIPT"
```

### Comment cela se r√©partit ?

Avec deux n≈ìuds √ó deux GPU ‚Üí **4 workers Optuna en parall√®le**.

Chaque worker traite un trial ind√©pendant.

---

## R√©cup√©rer le meilleur mod√®le

Vous pouvez lancer :

```bash
apptainer exec --bind /tmpdir,/work --nv /work/conteneurs/sessions-interactives/pytorch-24.02-py3-calmip-si.sif python check_best_model.py
```

Le fichier :

```python
import optuna
study = optuna.load_study("mnist_hpo", storage="sqlite:///study.db")
print(study.best_value)
print(study.best_params)
```

---

## Algorithmes d'optimisation avanc√©s dans Optuna

Optuna propose plusieurs moteurs de recherche d‚Äôhyperparam√®tres :

| Algorithme | Description | Recommand√© |
|-----------|-------------|------------|
| **TPE (par d√©faut)** | Tr√®s efficace, adaptatif | Recommand√© |
| **RandomSearch** | Basique mais robuste | petites exp√©riences |
| **GridSearch** | exhaustive | espaces petits |
| **CMA‚ÄëES** | optimisation √©volutive | grands espaces continus |
| **BruteForceSampler** | debug | jamais en production |
| **NSGA‚ÄëII** | optimisation multi‚Äëobjectifs | probl√®mes scientifiques |

### Exemple TPE (par d√©faut)
```python
study = optuna.create_study(direction="minimize", sampler=optuna.samplers.TPESampler())
```

### Exemple CMA‚ÄëES
```python
from optuna.samplers import CmaEsSampler
study = optuna.create_study(sampler=CmaEsSampler())
```

---

## Visualisations Optuna

Optuna permet de g√©n√©rer automatiquement des graphiques :

```python
optuna.visualization.plot_optimization_history(study)
optuna.visualization.plot_param_importances(study)
optuna.visualization.plot_parallel_coordinate(study)
```

---

## Adapter l‚Äôexemple √† des mod√®les plus grands (LLM)

Il suffit de remplacer le mod√®le MNIST :

```python
from transformers import T5ForConditionalGeneration, T5Config

def build_model(config):
    tconf = T5Config(
        d_model=config["hidden_size"],
        num_heads=config["num_heads"],
        num_layers=config["num_layers"]
    )
    return T5ForConditionalGeneration(tconf)
```

Et d√©finir un espace :

```python
"hidden_size": trial.suggest_categorical([512, 768, 1024]),
"num_layers": trial.suggest_int("num_layers", 4, 24),
"num_heads": trial.suggest_categorical([8, 12, 16]),
"lr": trial.suggest_float(1e-6, 1e-4, log=True),
```

---

## Lancer le job

```bash
sbatch run-optuna-multinode-Turpan.sh
```

Suivre la file :

```bash
squeue --me
```

Voir quels GPU sont utilis√©s :

```bash
placement --checkme
```

---

## Scalabilit√© attendue sur Turpan

Si vous lancez 500 trials avec 4 GPU :

‚Üí 4 trials simultan√©s  
‚Üí Optuna envoie un nouveau trial d√®s qu‚Äôun GPU se lib√®re  
‚Üí Temps total ‚âà (500 / 4) √ó dur√©e d‚Äôun entra√Ænement

Avec 8 GPU ‚Üí 8 trials simultan√©s  
Avec 16 GPU ‚Üí 16 trials simultan√©s

Optuna scale bien tant qu‚Äôil y a des trials √† lancer.

Ce document fournit un exemple complet utilisant MNIST, mais le sch√©ma peut √™tre √©tendu √† des mod√®les plus complexes comme des CNN plus profonds ou des mod√®les transformers.

---

